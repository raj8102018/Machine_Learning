{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444845b3-8f21-4f4f-922f-ae3abbd6b6af",
   "metadata": {},
   "source": [
    "# Intent Classification Using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c30bf4-131d-41b5-8805-f37876c74ae4",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "We are tryig to Classify Intent using Logistic Regression model on SNIPS Dataset. We are going to use different libraries like NLTK, Spacy and Gensim for preprocessing and then compare the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbba22ba-1e90-4094-b1bf-86804ba80482",
   "metadata": {},
   "source": [
    "### Importing libraries and Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa802f49-07e2-4a46-8adc-9a36a4f37195",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in d:\\conda\\lib\\site-packages (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\conda\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\conda\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\conda\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\conda\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\conda\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in d:\\conda\\lib\\site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in d:\\conda\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\conda\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\conda\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in d:\\conda\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in d:\\conda\\lib\\site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\conda\\lib\\site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\conda\\lib\\site-packages (from spacy) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\conda\\lib\\site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in d:\\conda\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in d:\\conda\\lib\\site-packages (from spacy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\conda\\lib\\site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\conda\\lib\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in d:\\conda\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in d:\\conda\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\conda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in d:\\conda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in d:\\conda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in d:\\conda\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in d:\\conda\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in d:\\conda\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\conda\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\conda\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\conda\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in d:\\conda\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in d:\\conda\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\conda\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in d:\\conda\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\conda\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\conda\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\conda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd61bc84-be77-4783-861a-624962e8cdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     - ------------------------------------- 0.5/12.8 MB 796.8 kB/s eta 0:00:16\n",
      "     - ------------------------------------- 0.5/12.8 MB 796.8 kB/s eta 0:00:16\n",
      "     - ------------------------------------- 0.5/12.8 MB 796.8 kB/s eta 0:00:16\n",
      "     -- ------------------------------------ 0.8/12.8 MB 516.0 kB/s eta 0:00:24\n",
      "     -- ------------------------------------ 0.8/12.8 MB 516.0 kB/s eta 0:00:24\n",
      "     -- ------------------------------------ 0.8/12.8 MB 516.0 kB/s eta 0:00:24\n",
      "     -- ------------------------------------ 0.8/12.8 MB 516.0 kB/s eta 0:00:24\n",
      "     --- ----------------------------------- 1.0/12.8 MB 437.6 kB/s eta 0:00:27\n",
      "     --- ----------------------------------- 1.0/12.8 MB 437.6 kB/s eta 0:00:27\n",
      "     --- ----------------------------------- 1.0/12.8 MB 437.6 kB/s eta 0:00:27\n",
      "     --- ----------------------------------- 1.0/12.8 MB 437.6 kB/s eta 0:00:27\n",
      "     --- ----------------------------------- 1.3/12.8 MB 401.8 kB/s eta 0:00:29\n",
      "     --- ----------------------------------- 1.3/12.8 MB 401.8 kB/s eta 0:00:29\n",
      "     --- ----------------------------------- 1.3/12.8 MB 401.8 kB/s eta 0:00:29\n",
      "     ---- ---------------------------------- 1.6/12.8 MB 403.3 kB/s eta 0:00:28\n",
      "     ---- ---------------------------------- 1.6/12.8 MB 403.3 kB/s eta 0:00:28\n",
      "     ---- ---------------------------------- 1.6/12.8 MB 403.3 kB/s eta 0:00:28\n",
      "     ----- --------------------------------- 1.8/12.8 MB 399.4 kB/s eta 0:00:28\n",
      "     ----- --------------------------------- 1.8/12.8 MB 399.4 kB/s eta 0:00:28\n",
      "     ----- --------------------------------- 1.8/12.8 MB 399.4 kB/s eta 0:00:28\n",
      "     ------ -------------------------------- 2.1/12.8 MB 412.0 kB/s eta 0:00:26\n",
      "     ------ -------------------------------- 2.1/12.8 MB 412.0 kB/s eta 0:00:26\n",
      "     ------ -------------------------------- 2.1/12.8 MB 412.0 kB/s eta 0:00:26\n",
      "     ------- ------------------------------- 2.4/12.8 MB 406.7 kB/s eta 0:00:26\n",
      "     ------- ------------------------------- 2.4/12.8 MB 406.7 kB/s eta 0:00:26\n",
      "     ------- ------------------------------- 2.4/12.8 MB 406.7 kB/s eta 0:00:26\n",
      "     ------- ------------------------------- 2.6/12.8 MB 417.1 kB/s eta 0:00:25\n",
      "     ------- ------------------------------- 2.6/12.8 MB 417.1 kB/s eta 0:00:25\n",
      "     -------- ------------------------------ 2.9/12.8 MB 432.4 kB/s eta 0:00:23\n",
      "     --------- ----------------------------- 3.1/12.8 MB 451.2 kB/s eta 0:00:22\n",
      "     --------- ----------------------------- 3.1/12.8 MB 451.2 kB/s eta 0:00:22\n",
      "     --------- ----------------------------- 3.1/12.8 MB 451.2 kB/s eta 0:00:22\n",
      "     --------- ----------------------------- 3.1/12.8 MB 451.2 kB/s eta 0:00:22\n",
      "     ---------- ---------------------------- 3.4/12.8 MB 441.5 kB/s eta 0:00:22\n",
      "     ---------- ---------------------------- 3.4/12.8 MB 441.5 kB/s eta 0:00:22\n",
      "     ---------- ---------------------------- 3.4/12.8 MB 441.5 kB/s eta 0:00:22\n",
      "     ----------- --------------------------- 3.7/12.8 MB 433.6 kB/s eta 0:00:22\n",
      "     ----------- --------------------------- 3.7/12.8 MB 433.6 kB/s eta 0:00:22\n",
      "     ----------- --------------------------- 3.7/12.8 MB 433.6 kB/s eta 0:00:22\n",
      "     ----------- --------------------------- 3.7/12.8 MB 433.6 kB/s eta 0:00:22\n",
      "     ----------- --------------------------- 3.9/12.8 MB 424.7 kB/s eta 0:00:21\n",
      "     ----------- --------------------------- 3.9/12.8 MB 424.7 kB/s eta 0:00:21\n",
      "     ----------- --------------------------- 3.9/12.8 MB 424.7 kB/s eta 0:00:21\n",
      "     ------------ -------------------------- 4.2/12.8 MB 420.8 kB/s eta 0:00:21\n",
      "     ------------ -------------------------- 4.2/12.8 MB 420.8 kB/s eta 0:00:21\n",
      "     ------------ -------------------------- 4.2/12.8 MB 420.8 kB/s eta 0:00:21\n",
      "     ------------- ------------------------- 4.5/12.8 MB 426.7 kB/s eta 0:00:20\n",
      "     ------------- ------------------------- 4.5/12.8 MB 426.7 kB/s eta 0:00:20\n",
      "     -------------- ------------------------ 4.7/12.8 MB 434.8 kB/s eta 0:00:19\n",
      "     -------------- ------------------------ 4.7/12.8 MB 434.8 kB/s eta 0:00:19\n",
      "     -------------- ------------------------ 4.7/12.8 MB 434.8 kB/s eta 0:00:19\n",
      "     --------------- ----------------------- 5.0/12.8 MB 433.3 kB/s eta 0:00:19\n",
      "     --------------- ----------------------- 5.0/12.8 MB 433.3 kB/s eta 0:00:19\n",
      "     --------------- ----------------------- 5.2/12.8 MB 440.9 kB/s eta 0:00:18\n",
      "     --------------- ----------------------- 5.2/12.8 MB 440.9 kB/s eta 0:00:18\n",
      "     ---------------- ---------------------- 5.5/12.8 MB 448.6 kB/s eta 0:00:17\n",
      "     ---------------- ---------------------- 5.5/12.8 MB 448.6 kB/s eta 0:00:17\n",
      "     ----------------- --------------------- 5.8/12.8 MB 453.4 kB/s eta 0:00:16\n",
      "     ----------------- --------------------- 5.8/12.8 MB 453.4 kB/s eta 0:00:16\n",
      "     ----------------- --------------------- 5.8/12.8 MB 453.4 kB/s eta 0:00:16\n",
      "     ------------------ -------------------- 6.0/12.8 MB 451.8 kB/s eta 0:00:15\n",
      "     ------------------ -------------------- 6.0/12.8 MB 451.8 kB/s eta 0:00:15\n",
      "     ------------------ -------------------- 6.0/12.8 MB 451.8 kB/s eta 0:00:15\n",
      "     ------------------- ------------------- 6.3/12.8 MB 449.7 kB/s eta 0:00:15\n",
      "     ------------------- ------------------- 6.3/12.8 MB 449.7 kB/s eta 0:00:15\n",
      "     ------------------- ------------------- 6.6/12.8 MB 453.4 kB/s eta 0:00:14\n",
      "     ------------------- ------------------- 6.6/12.8 MB 453.4 kB/s eta 0:00:14\n",
      "     -------------------- ------------------ 6.8/12.8 MB 458.4 kB/s eta 0:00:14\n",
      "     -------------------- ------------------ 6.8/12.8 MB 458.4 kB/s eta 0:00:14\n",
      "     -------------------- ------------------ 6.8/12.8 MB 458.4 kB/s eta 0:00:14\n",
      "     -------------------- ------------------ 6.8/12.8 MB 458.4 kB/s eta 0:00:14\n",
      "     --------------------- ----------------- 7.1/12.8 MB 452.0 kB/s eta 0:00:13\n",
      "     --------------------- ----------------- 7.1/12.8 MB 452.0 kB/s eta 0:00:13\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 454.8 kB/s eta 0:00:13\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 454.8 kB/s eta 0:00:13\n",
      "     ---------------------- ---------------- 7.3/12.8 MB 454.8 kB/s eta 0:00:13\n",
      "     ----------------------- --------------- 7.6/12.8 MB 457.4 kB/s eta 0:00:12\n",
      "     ----------------------- --------------- 7.6/12.8 MB 457.4 kB/s eta 0:00:12\n",
      "     ----------------------- --------------- 7.6/12.8 MB 457.4 kB/s eta 0:00:12\n",
      "     ----------------------- --------------- 7.6/12.8 MB 457.4 kB/s eta 0:00:12\n",
      "     ----------------------- --------------- 7.9/12.8 MB 448.8 kB/s eta 0:00:12\n",
      "     ----------------------- --------------- 7.9/12.8 MB 448.8 kB/s eta 0:00:12\n",
      "     ----------------------- --------------- 7.9/12.8 MB 448.8 kB/s eta 0:00:12\n",
      "     ------------------------ -------------- 8.1/12.8 MB 449.0 kB/s eta 0:00:11\n",
      "     ------------------------ -------------- 8.1/12.8 MB 449.0 kB/s eta 0:00:11\n",
      "     ------------------------ -------------- 8.1/12.8 MB 449.0 kB/s eta 0:00:11\n",
      "     ------------------------- ------------- 8.4/12.8 MB 445.3 kB/s eta 0:00:10\n",
      "     ------------------------- ------------- 8.4/12.8 MB 445.3 kB/s eta 0:00:10\n",
      "     ------------------------- ------------- 8.4/12.8 MB 445.3 kB/s eta 0:00:10\n",
      "     -------------------------- ------------ 8.7/12.8 MB 446.3 kB/s eta 0:00:10\n",
      "     -------------------------- ------------ 8.7/12.8 MB 446.3 kB/s eta 0:00:10\n",
      "     -------------------------- ------------ 8.7/12.8 MB 446.3 kB/s eta 0:00:10\n",
      "     --------------------------- ----------- 8.9/12.8 MB 446.8 kB/s eta 0:00:09\n",
      "     --------------------------- ----------- 8.9/12.8 MB 446.8 kB/s eta 0:00:09\n",
      "     --------------------------- ----------- 8.9/12.8 MB 446.8 kB/s eta 0:00:09\n",
      "     --------------------------- ----------- 9.2/12.8 MB 445.6 kB/s eta 0:00:09\n",
      "     ---------------------------- ---------- 9.4/12.8 MB 451.0 kB/s eta 0:00:08\n",
      "     ---------------------------- ---------- 9.4/12.8 MB 451.0 kB/s eta 0:00:08\n",
      "     ---------------------------- ---------- 9.4/12.8 MB 451.0 kB/s eta 0:00:08\n",
      "     ----------------------------- --------- 9.7/12.8 MB 451.7 kB/s eta 0:00:07\n",
      "     ----------------------------- --------- 9.7/12.8 MB 451.7 kB/s eta 0:00:07\n",
      "     ----------------------------- -------- 10.0/12.8 MB 454.4 kB/s eta 0:00:07\n",
      "     ----------------------------- -------- 10.0/12.8 MB 454.4 kB/s eta 0:00:07\n",
      "     ------------------------------ ------- 10.2/12.8 MB 457.3 kB/s eta 0:00:06\n",
      "     ------------------------------ ------- 10.2/12.8 MB 457.3 kB/s eta 0:00:06\n",
      "     ------------------------------- ------ 10.5/12.8 MB 459.8 kB/s eta 0:00:06\n",
      "     ------------------------------- ------ 10.5/12.8 MB 459.8 kB/s eta 0:00:06\n",
      "     ------------------------------- ------ 10.5/12.8 MB 459.8 kB/s eta 0:00:06\n",
      "     ------------------------------- ------ 10.7/12.8 MB 462.2 kB/s eta 0:00:05\n",
      "     ------------------------------- ------ 10.7/12.8 MB 462.2 kB/s eta 0:00:05\n",
      "     -------------------------------- ----- 11.0/12.8 MB 465.1 kB/s eta 0:00:04\n",
      "     --------------------------------- ---- 11.3/12.8 MB 468.8 kB/s eta 0:00:04\n",
      "     --------------------------------- ---- 11.3/12.8 MB 468.8 kB/s eta 0:00:04\n",
      "     --------------------------------- ---- 11.3/12.8 MB 468.8 kB/s eta 0:00:04\n",
      "     --------------------------------- ---- 11.3/12.8 MB 468.8 kB/s eta 0:00:04\n",
      "     ---------------------------------- --- 11.5/12.8 MB 466.6 kB/s eta 0:00:03\n",
      "     ---------------------------------- --- 11.5/12.8 MB 466.6 kB/s eta 0:00:03\n",
      "     ---------------------------------- --- 11.5/12.8 MB 466.6 kB/s eta 0:00:03\n",
      "     ----------------------------------- -- 11.8/12.8 MB 463.7 kB/s eta 0:00:03\n",
      "     ----------------------------------- -- 11.8/12.8 MB 463.7 kB/s eta 0:00:03\n",
      "     ----------------------------------- -- 12.1/12.8 MB 467.5 kB/s eta 0:00:02\n",
      "     ----------------------------------- -- 12.1/12.8 MB 467.5 kB/s eta 0:00:02\n",
      "     ------------------------------------ - 12.3/12.8 MB 468.6 kB/s eta 0:00:02\n",
      "     ------------------------------------ - 12.3/12.8 MB 468.6 kB/s eta 0:00:02\n",
      "     ------------------------------------ - 12.3/12.8 MB 468.6 kB/s eta 0:00:02\n",
      "     ------------------------------------ - 12.3/12.8 MB 468.6 kB/s eta 0:00:02\n",
      "     -------------------------------------  12.6/12.8 MB 465.7 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.6/12.8 MB 465.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 12.8/12.8 MB 465.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in d:\\conda\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in d:\\conda\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in d:\\conda\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\conda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in d:\\conda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in d:\\conda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in d:\\conda\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in d:\\conda\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: colorama in d:\\conda\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\conda\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\conda\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\conda\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in d:\\conda\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in d:\\conda\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\conda\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in d:\\conda\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\conda\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\conda\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\conda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.0)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b0b98d7-c56e-41fa-8da5-981cf8c35c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1888343-4f43-4180-a1e7-c6b45dd88832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc63d2f6-a9ef-40c2-9390-b5d1dae676e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "299544b1-cf01-4936-bc3a-7675d2a85ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/sonos-nlu-benchmark/snips_built_in_intents/data/train-00000-of-00001.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ebafb3-c2b1-42ca-840d-2c433181d894",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "Here let's get an understanding of the basic structure of the dataset before preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac419480-307f-4f91-9851-6b915eb4cb58",
   "metadata": {},
   "source": [
    "This dataset was used for comparing voice assistants by SNIPS and SVE teams. The dataset contains multiple utterances over 10 intent classes as follows:\n",
    " - '0': ComparePlaces\n",
    " - '1': RequestRide\n",
    " - '2': GetWeather\n",
    " - '3': SearchPlace\n",
    " - '4': GetPlaceDetails\n",
    " - '5': ShareCurrentLocation\n",
    " - '6': GetTrafficInformation\n",
    " - '7': BookRestaurant\n",
    " - '8': GetDirections'\n",
    " - '9': ShareETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17b04aeb-c14c-4d4e-9aec-c44feaec77f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Share my location with Hillary's sister</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Send my current location to my father</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Share my current location with Jim</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Send my location to my husband</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Send my location</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text  label\n",
       "0  Share my location with Hillary's sister      5\n",
       "1    Send my current location to my father      5\n",
       "2       Share my current location with Jim      5\n",
       "3           Send my location to my husband      5\n",
       "4                         Send my location      5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e54243a1-c2b3-405c-9b57-02320fe81956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e83796d-b289-44db-8b56-30f7775ddf7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 328 entries, 0 to 327\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    328 non-null    object\n",
      " 1   label   328 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 5.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb294cf1-5d04-4f9c-92be-cbaf94d80288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74f67ce6-1506-4bc8-be55-b2aceda54524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>328.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.762195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.697519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label\n",
       "count  328.000000\n",
       "mean     4.762195\n",
       "std      2.697519\n",
       "min      0.000000\n",
       "25%      2.000000\n",
       "50%      4.000000\n",
       "75%      7.000000\n",
       "max      9.000000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "127a4bd0-5cbb-4a10-b2dc-8682fb5ad428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum() #check for duplicates. if any, drop using df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0753a93d-cffd-4e60-a8c2-444face90f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "7    70\n",
       "4    50\n",
       "2    42\n",
       "8    35\n",
       "3    28\n",
       "1    26\n",
       "9    22\n",
       "6    20\n",
       "0    19\n",
       "5    16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde867ca-2fd4-4940-a470-35a15a3ab337",
   "metadata": {},
   "source": [
    "We can see bookrestaurant (7) and get place details (0) amongst the available utterances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6469e42-8c79-4be7-9972-efeebc27acf7",
   "metadata": {},
   "source": [
    "Below we visualize the counts of each label using seaborn by plotting a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07141210-f84f-412c-ad40-ac2f6b19d59c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=df, x='label')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b3a2db-aab1-47ae-baf9-4c7a7f29219a",
   "metadata": {},
   "source": [
    "We further explore the text data in the dataset below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ec260fe-7368-4e87-9409-5a6624e4fc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    328.000000\n",
       "mean      47.228659\n",
       "std       15.567143\n",
       "min       10.000000\n",
       "25%       36.000000\n",
       "50%       47.000000\n",
       "75%       58.000000\n",
       "max       93.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.len().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ee96b8-eadb-4b91-9fe3-0006f3a6b71b",
   "metadata": {},
   "source": [
    "## Preprocessing the data\n",
    "Let's preprocess the data using different libraries before feeding it our machine learning model for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321d1e0c-2e35-4dd5-ba72-d37a739a7641",
   "metadata": {},
   "source": [
    "### Preprocessing using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e2c20f-a19d-4e73-9370-7f21bf49964e",
   "metadata": {},
   "source": [
    "we use punkt tokenizer models from NLTK library, this is used for tokenizing text into words or sentences. It provides pre-trained models that are necessary for tokenization.\n",
    "we access stopwords module to filterout stopwords\n",
    "word_tokenize function to split a text into tokens\n",
    "We use porterstemer, a stemming algorithm to reduce words to their root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "776fe871-a95f-4329-bb12-ad4b1ff37f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Rajendra Prasad\n",
      "[nltk_data]     K\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Rajendra Prasad\n",
      "[nltk_data]     K\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a9b321c-03c4-4ea9-bdc7-eaaab01b6713",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) #create a set of stop words in english\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def nltk_preprocess(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    words = [stemmer.stem(word) for word in words if word.isalnum() and word not in stop_words]\n",
    "    # used list comprehension to check if a word is alphanumeric or not and if it is a stop word\n",
    "    return ' '.join(words)\n",
    "    #every word is joined and a string is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3b799fa0-a5b2-494b-87e5-b46f0b1a81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nltk = df.copy()\n",
    "df_nltk['processed_text'] = df_nltk['text'].apply(nltk_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "958a1ea5-6118-4d68-8c07-4c8809d4cb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Share my location with Hillary's sister</td>\n",
       "      <td>5</td>\n",
       "      <td>share locat hillari sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Send my current location to my father</td>\n",
       "      <td>5</td>\n",
       "      <td>send current locat father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Share my current location with Jim</td>\n",
       "      <td>5</td>\n",
       "      <td>share current locat jim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Send my location to my husband</td>\n",
       "      <td>5</td>\n",
       "      <td>send locat husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Send my location</td>\n",
       "      <td>5</td>\n",
       "      <td>send locat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text  label              processed_text\n",
       "0  Share my location with Hillary's sister      5  share locat hillari sister\n",
       "1    Send my current location to my father      5   send current locat father\n",
       "2       Share my current location with Jim      5     share current locat jim\n",
       "3           Send my location to my husband      5          send locat husband\n",
       "4                         Send my location      5                  send locat"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nltk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9001ba8-90de-41c7-8186-1420fd1e4b0c",
   "metadata": {},
   "source": [
    "### Preprocessing using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "90beb740-4bbf-4629-9a22-91a01a2b5b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "143868d5-c298-45ae-b9f8-ee34b6dcf26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Share my location with Hillary's sister</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Send my current location to my father</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Share my current location with Jim</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Send my location to my husband</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Send my location</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text  label\n",
       "0  Share my location with Hillary's sister      5\n",
       "1    Send my current location to my father      5\n",
       "2       Share my current location with Jim      5\n",
       "3           Send my location to my husband      5\n",
       "4                         Send my location      5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spacy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d5907-84a6-4507-95e0-aa871db9fbf1",
   "metadata": {},
   "source": [
    "We use 'en_core_web_sm' a small english model which includes tokenization, pos tagging, lemmatization etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ed7faaf4-2276-4f62-b167-e4a2b3b8f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm') \n",
    "\n",
    "def spacy_preprocess(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "    #token.lemma_ gets the base form of the word.\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c2f2f380-7bfb-41a3-8be9-d3bd0588e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy['processed_text'] = df_spacy['text'].apply(spacy_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fdf74f5d-086f-40f2-84a2-49fe97ff46de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Share my location with Hillary's sister</td>\n",
       "      <td>5</td>\n",
       "      <td>share location hillary sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Send my current location to my father</td>\n",
       "      <td>5</td>\n",
       "      <td>send current location father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Share my current location with Jim</td>\n",
       "      <td>5</td>\n",
       "      <td>share current location jim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Send my location to my husband</td>\n",
       "      <td>5</td>\n",
       "      <td>send location husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Send my location</td>\n",
       "      <td>5</td>\n",
       "      <td>send location</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text  label  \\\n",
       "0  Share my location with Hillary's sister      5   \n",
       "1    Send my current location to my father      5   \n",
       "2       Share my current location with Jim      5   \n",
       "3           Send my location to my husband      5   \n",
       "4                         Send my location      5   \n",
       "\n",
       "                  processed_text  \n",
       "0  share location hillary sister  \n",
       "1   send current location father  \n",
       "2     share current location jim  \n",
       "3          send location husband  \n",
       "4                  send location  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spacy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df75243d-9f1c-40d4-8324-2c09f7218e68",
   "metadata": {},
   "source": [
    "### Preprocessing using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6589832e-cf42-4a33-8c76-38c7eaad4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gensim = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fbb3b36b-e279-42b4-a2ed-8651ccba2925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Share my location with Hillary's sister</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Send my current location to my father</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Share my current location with Jim</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Send my location to my husband</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Send my location</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text  label\n",
       "0  Share my location with Hillary's sister      5\n",
       "1    Send my current location to my father      5\n",
       "2       Share my current location with Jim      5\n",
       "3           Send my location to my husband      5\n",
       "4                         Send my location      5"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gensim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f81911b1-70ac-4808-b5fc-cb48dd6e991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensim_preprocess(text):\n",
    "    words = [word for word in simple_preprocess(text, deacc=True) if word not in STOPWORDS]\n",
    "    return ' '.join(words)\n",
    "    #simple_preprocess function does the tokenization, lowercasing and punctuation removal here\n",
    "    #deacc = true removes punctuation and special characters from tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "048f1e5f-8ed3-4f09-9bcd-b1d5beead869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gensim['processed_text'] = df_gensim['text'].apply(gensim_preprocess) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b04180c0-445b-4857-94aa-baf71bdefb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Share my location with Hillary's sister</td>\n",
       "      <td>5</td>\n",
       "      <td>share location hillary sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Send my current location to my father</td>\n",
       "      <td>5</td>\n",
       "      <td>send current location father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Share my current location with Jim</td>\n",
       "      <td>5</td>\n",
       "      <td>share current location jim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Send my location to my husband</td>\n",
       "      <td>5</td>\n",
       "      <td>send location husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Send my location</td>\n",
       "      <td>5</td>\n",
       "      <td>send location</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text  label  \\\n",
       "0  Share my location with Hillary's sister      5   \n",
       "1    Send my current location to my father      5   \n",
       "2       Share my current location with Jim      5   \n",
       "3           Send my location to my husband      5   \n",
       "4                         Send my location      5   \n",
       "\n",
       "                  processed_text  \n",
       "0  share location hillary sister  \n",
       "1   send current location father  \n",
       "2     share current location jim  \n",
       "3          send location husband  \n",
       "4                  send location  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gensim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb2f565-496f-49d5-bb72-5abf8644f3e7",
   "metadata": {},
   "source": [
    "Comparing the preprocessed texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e719af-fba1-441e-ae33-1ecc7bc812b7",
   "metadata": {},
   "source": [
    "Let's find the longest entry in text column to compare the preprocessing done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "51cee541-4911-4591-97f5-638554128e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_text = df['text'].max()\n",
    "index_longest_text = df[df['text'] == longest_text].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9dec619b-5ddb-4b9f-8419-9cf752991ffe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest text:  Will it rain tomorrow near my all day event?\n",
      "longest text index:  323\n"
     ]
    }
   ],
   "source": [
    "print(\"longest text: \", longest_text)\n",
    "print(\"longest text index: \", index_longest_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "98463d3d-e677-4703-82aa-d9f12ea5575e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: Will it rain tomorrow near my all day event?\n",
      "NLTK Processed Text: rain tomorrow near day event\n",
      "spaCy Processed Text: rain tomorrow near day event\n",
      "Gensim Processed Text: rain tomorrow near day event\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Text:\", df['text'][index_longest_text])\n",
    "print(\"NLTK Processed Text:\", df_nltk['processed_text'][index_longest_text])\n",
    "print(\"spaCy Processed Text:\", df_spacy['processed_text'][index_longest_text])\n",
    "print(\"Gensim Processed Text:\", df_gensim['processed_text'][index_longest_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e467d2ba-1b06-42e5-96ff-da930ee84a73",
   "metadata": {},
   "source": [
    "It doesn't seem to be differing much as of now, let's compare the first entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b187aed9-9286-4b49-8fa2-e39a1a115394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: Share my location with Hillary's sister\n",
      "NLTK Processed Text: share locat hillari sister\n",
      "spaCy Processed Text: share location hillary sister\n",
      "Gensim Processed Text: share location hillary sister\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Text:\", df['text'][0])\n",
    "print(\"NLTK Processed Text:\", df_nltk['processed_text'][0])\n",
    "print(\"spaCy Processed Text:\", df_spacy['processed_text'][0])\n",
    "print(\"Gensim Processed Text:\", df_gensim['processed_text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea4af0e-3430-44cc-982d-54fc571214f0",
   "metadata": {},
   "source": [
    "Minor difference can be seen here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ff9e4-4606-4f00-9fbb-75169078f13e",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f60688e-ed15-49c1-995e-bdb55cc2418b",
   "metadata": {},
   "source": [
    "We are going to use TF-IDF with N-grams here to capture context,\n",
    "Intent Classification requires understanding phrases or common patterns, which n-grams can help in,\n",
    "TF-IDF helps in weighing the importance of n-grams by considering their frequency in a text input and across entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf06dc1f-48b7-48a0-aa03-83946797b63e",
   "metadata": {},
   "source": [
    "### Separate Features and Labels for Each copy we made"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c9417c-37c4-486a-ba09-f996fa57ad58",
   "metadata": {},
   "source": [
    "since we made different copies of dataframe for comparing preprocessing methods, we do the same here for extracting features for all the copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8ad2fd65-5fc1-47a0-a92d-37eca000792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for raw data\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# For NLTK preprocessing\n",
    "X_nltk = df_nltk['processed_text']\n",
    "y_nltk = df_nltk['label']\n",
    "\n",
    "# For spaCy preprocessing\n",
    "X_spacy = df_spacy['processed_text']\n",
    "y_spacy = df_spacy['label']\n",
    "\n",
    "# For gensim preprocessing\n",
    "X_gensim = df_gensim['processed_text']\n",
    "y_gensim = df_gensim['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea2a330-bdc2-46bf-a422-e2cf259708ce",
   "metadata": {},
   "source": [
    "### Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b1ee74-3265-452a-8710-d3c2b7610648",
   "metadata": {},
   "source": [
    "We split each preprocessed dataset into training and testing sets below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "41ea566a-725a-46ec-93aa-3e0d16467f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For raw data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# For NLTK preprocessing\n",
    "X_train_nltk, X_test_nltk, y_train_nltk, y_test_nltk = train_test_split(X_nltk, y_nltk, test_size=0.2, random_state=42)\n",
    "\n",
    "# For spaCy preprocessing\n",
    "X_train_spacy, X_test_spacy, y_train_spacy, y_test_spacy = train_test_split(X_spacy, y_spacy, test_size=0.2, random_state=42)\n",
    "\n",
    "# For Gensim preprocessing\n",
    "X_train_gensim, X_test_gensim, y_train_gensim, y_test_gensim = train_test_split(X_gensim, y_gensim, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c99bc7-c83a-4e4b-8d57-a0539fcd1008",
   "metadata": {},
   "source": [
    "### Vectorize the Text Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b2e57a-6ecf-4451-8217-dace6fdff07f",
   "metadata": {},
   "source": [
    "Now we convert the text data after splitting it into training and testing sets to numerical features using TF-IDF with N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ad2a1fb8-57fe-41cf-9a19-7f3940dba9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Initialize TF-IDF Vectorizer and transform the text data\n",
    "# For raw data\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# For NLTK preprocessing\n",
    "vectorizer_nltk = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train_nltk_tfidf = vectorizer_nltk.fit_transform(X_train_nltk)\n",
    "X_test_nltk_tfidf = vectorizer_nltk.transform(X_test_nltk)\n",
    "\n",
    "# For spaCy preprocessing\n",
    "vectorizer_spacy = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train_spacy_tfidf = vectorizer_spacy.fit_transform(X_train_spacy)\n",
    "X_test_spacy_tfidf = vectorizer_spacy.transform(X_test_spacy)\n",
    "\n",
    "# For Gensim preprocessing\n",
    "vectorizer_gensim = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train_gensim_tfidf = vectorizer_gensim.fit_transform(X_train_gensim)\n",
    "X_test_gensim_tfidf = vectorizer_gensim.transform(X_test_gensim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750fd8b-99ab-4e1b-9811-2c395592925a",
   "metadata": {},
   "source": [
    "we can see all the members using the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "76eaaf22-b897-4600-b315-0fda65b31506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_build_request_for_signature',\n",
       " '_char_ngrams',\n",
       " '_char_wb_ngrams',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_check_params',\n",
       " '_check_stop_words_consistency',\n",
       " '_check_vocabulary',\n",
       " '_count_vocab',\n",
       " '_doc_link_module',\n",
       " '_doc_link_template',\n",
       " '_doc_link_url_param_generator',\n",
       " '_get_default_requests',\n",
       " '_get_doc_link',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_limit_features',\n",
       " '_more_tags',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_sort_features',\n",
       " '_stop_words_id',\n",
       " '_tfidf',\n",
       " '_validate_data',\n",
       " '_validate_ngram_range',\n",
       " '_validate_params',\n",
       " '_validate_vocabulary',\n",
       " '_warn_for_unused_params',\n",
       " '_white_spaces',\n",
       " '_word_ngrams',\n",
       " 'analyzer',\n",
       " 'binary',\n",
       " 'build_analyzer',\n",
       " 'build_preprocessor',\n",
       " 'build_tokenizer',\n",
       " 'decode',\n",
       " 'decode_error',\n",
       " 'dtype',\n",
       " 'encoding',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'fixed_vocabulary_',\n",
       " 'get_feature_names_out',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'get_stop_words',\n",
       " 'idf_',\n",
       " 'input',\n",
       " 'inverse_transform',\n",
       " 'lowercase',\n",
       " 'max_df',\n",
       " 'max_features',\n",
       " 'min_df',\n",
       " 'ngram_range',\n",
       " 'norm',\n",
       " 'preprocessor',\n",
       " 'set_fit_request',\n",
       " 'set_params',\n",
       " 'set_transform_request',\n",
       " 'smooth_idf',\n",
       " 'stop_words',\n",
       " 'stop_words_',\n",
       " 'strip_accents',\n",
       " 'sublinear_tf',\n",
       " 'token_pattern',\n",
       " 'tokenizer',\n",
       " 'transform',\n",
       " 'use_idf',\n",
       " 'vocabulary',\n",
       " 'vocabulary_']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40433d15-82e9-46df-8524-57b4df920af5",
   "metadata": {},
   "source": [
    "we can check the vocabulary for any of the above, let's do it for spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3cd7a7-f312-45dd-bc9c-08d0ee521d00",
   "metadata": {},
   "source": [
    "We can see the vocabulary using the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "55e19f34-8a42-4317-b4db-f9a985e2951b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'taxi': 998, 'emmit': 280, 'irish': 474, 'pub': 782, 'taxi emmit': 1001, 'emmit irish': 281, 'irish pub': 475, 'cheap': 140, 'restaurant': 820, 'close': 172, 'hotel': 462, 'cheap restaurant': 144, 'restaurant close': 825, 'close hotel': 173, 'favorite': 325, 'bar': 49, 'well': 1124, 'donut': 265, 'favorite bar': 326, 'bar well': 55, 'well donut': 1125, 'donut pub': 266, 'book': 72, 'table': 971, 'people': 727, 'sushi': 964, 'place': 746, 'tomorrow': 1029, 'night': 672, 'book table': 77, 'table people': 988, 'people sushi': 735, 'sushi place': 965, 'place tomorrow': 760, 'tomorrow night': 1033, 'find': 329, 'dinner': 230, 'tonight': 1035, 'find table': 344, 'table dinner': 977, 'dinner tonight': 234, 'direction': 235, 'tulsa': 1060, 'road': 853, 'direction tulsa': 256, 'tulsa road': 1061, 'opening': 691, 'hour': 468, 'tell': 1006, 'opening hour': 692, 'hour tell': 469, 'cycling': 203, 'chelsea': 146, 'market': 592, 'cycling direction': 204, 'direction chelsea': 238, 'chelsea market': 148, 'need': 663, 'reservation': 805, 'quince': 789, 'need reservation': 665, 'reservation quince': 815, 'minute': 613, 'avenue': 38, 'need taxi': 667, 'taxi minute': 1002, 'minute avenue': 614, 'good': 405, 'expensive': 302, 'japanese': 485, 'near': 638, 'work': 1143, 'find good': 335, 'good expensive': 410, 'expensive japanese': 305, 'japanese restaurant': 486, 'restaurant near': 832, 'near work': 658, 'friday': 361, 'pm': 765, 'katz': 508, 'delicatessen': 221, 'table friday': 978, 'friday pm': 363, 'pm people': 767, 'people katz': 730, 'katz delicatessen': 509, 'wifi': 1131, 'airbnb': 9, 'table restaurant': 989, 'restaurant wifi': 840, 'wifi near': 1133, 'near airbnb': 639, 'fry': 370, 'chicken': 151, 'fast': 320, 'food': 350, 'good fry': 412, 'fry chicken': 371, 'chicken restaurant': 152, 'restaurant fast': 827, 'fast food': 321, 'send': 882, 'message': 603, 'michael': 608, 'eta': 291, 'send message': 886, 'message michael': 606, 'michael eta': 609, 'theatre': 1012, 'belasco': 64, 'majestic': 587, 'close theatre': 177, 'theatre belasco': 1013, 'belasco theatre': 65, 'theatre majestic': 1014, 'majestic theatre': 588, 'drive': 271, 'tavern': 996, 'green': 424, 'drive direction': 272, 'direction tavern': 255, 'tavern green': 997, 'go': 391, 'week': 1120, 'people restaurant': 734, 'restaurant go': 828, 'go week': 400, 'lebanese': 530, 'nearby': 659, 'lunch': 579, 'party': 717, 'reservation lebanese': 811, 'lebanese restaurant': 531, 'restaurant nearby': 833, 'nearby lunch': 662, 'lunch party': 581, 'home': 457, 'like': 533, 'outside': 699, 'like outside': 542, 'find taxi': 345, 'want': 1095, 'photo': 741, 'want photo': 1100, 'photo place': 743, 'place go': 752, 'go tonight': 399, 'umbrella': 1067, 'umbrella tomorrow': 1068, 'share': 895, 'location': 550, 'boyfriend': 91, 'share location': 901, 'location boyfriend': 551, 'boyfriend home': 92, 'uber': 1062, 'uber dinner': 1063, 'dot': 267, 'dash': 206, 'lose': 571, 'lake': 521, 'dot dash': 268, 'dash cheap': 207, 'cheap lose': 142, 'lose lake': 572, 'vertigo': 1083, 'sky': 915, 'lounge': 573, 'usually': 1075, 'new': 669, 'york': 1150, 'vertigo sky': 1084, 'sky lounge': 916, 'lounge expensive': 574, 'expensive bar': 303, 'bar usually': 54, 'usually new': 1076, 'new york': 671, 'traffic': 1041, 'portion': 771, 'client': 170, 'meeting': 597, 'traffic portion': 1049, 'portion go': 772, 'go client': 392, 'client meeting': 171, 'john': 500, 'message john': 605, 'john tell': 503, 'plan': 761, 'slim': 917, 'plan slim': 762, 'slim tonight': 918, 'transit': 1054, 'barcelona': 56, 'wine': 1139, 'transit direction': 1055, 'direction barcelona': 236, 'barcelona wine': 57, 'wine bar': 1140, 'outdoor': 697, 'leave': 528, 'find outdoor': 336, 'outdoor table': 698, 'table leave': 984, 'disneyworld': 259, 'avoid': 40, 'direction disneyworld': 240, 'disneyworld avoid': 260, 'avoid traffic': 43, 'cafe': 125, 'gitane': 387, 'cafe gitane': 126, 'gitane wifi': 388, 'cab': 119, 'need cab': 664, 'cab work': 124, 'rao': 800, 'crowd': 197, 'rao crowd': 801, 'walk': 1090, 'christmas': 163, 'citymapper': 167, 'walk direction': 1092, 'direction christmas': 239, 'christmas party': 164, 'party citymapper': 719, 'seafood': 877, 'golden': 402, 'bridge': 95, 'find cheap': 331, 'cheap seafood': 145, 'seafood restaurant': 878, 'near golden': 644, 'golden bridge': 403, 'group': 429, 'west': 1128, 'village': 1088, 'table group': 980, 'group near': 430, 'near west': 657, 'west village': 1130, 'village tomorrow': 1089, 'accident': 0, 'expect': 299, 'cousin': 193, 'accident expect': 2, 'expect cousin': 300, 'cousin place': 194, 'deli': 219, 'mission': 615, 'dolore': 261, 'park': 711, 'table good': 979, 'good deli': 409, 'deli near': 220, 'near mission': 648, 'mission dolore': 616, 'dolore park': 262, 'park lunch': 713, 'direction john': 246, 'john place': 502, 'place leave': 754, 'leave pm': 529, 'table near': 985, 'near sushi': 653, 'sushi restaurant': 966, 'restaurant pm': 834, 'far': 315, 'nomad': 675, 'far nomad': 319, 'nomad bar': 676, 'lyft': 583, 'car': 128, 'greene': 425, 'street': 955, 'book lyft': 74, 'lyft car': 584, 'car greene': 129, 'greene street': 426, 'jo': 492, 'lori': 567, 'close jo': 174, 'jo lori': 493, 'lori place': 568, 'jam': 482, 'traffic jam': 1046, 'jam avenue': 483, 'rain': 791, 'go rain': 394, 'rain tomorrow': 795, 'airbnb close': 10, 'close john': 175, 'john hotel': 501, 'trump': 1058, 'tower': 1036, 'want table': 1102, 'good japanese': 414, 'near trump': 655, 'trump tower': 1059, 'eat': 274, 'burger': 111, 'soho': 922, 'eat good': 277, 'good burger': 407, 'burger soho': 112, 'la': 516, 'chine': 157, 'dinner la': 232, 'la chine': 517, 'surf': 962, 'lesson': 532, 'direction surf': 254, 'surf lesson': 963, 'galli': 375, 'reservation people': 814, 'people galli': 729, 'galli friday': 377, 'friday night': 362, 'gershwin': 381, 'park gershwin': 712, 'gershwin theatre': 382, 'store': 953, 'sia': 907, 'buy': 117, 'champagne': 139, 'find store': 343, 'store near': 954, 'near sia': 651, 'sia place': 908, 'place buy': 749, 'buy champagne': 118, 'current': 201, 'friend': 366, 'meet': 595, 'send current': 883, 'current location': 202, 'location friend': 553, 'friend meet': 367, 'swing': 969, 'pony': 769, 'ride': 847, 'aunt': 36, 'park swing': 714, 'swing pony': 970, 'pony ride': 770, 'ride aunt': 849, 'aunt place': 37, 'office': 685, 'manager': 589, 'noon': 677, 'location office': 557, 'office manager': 686, 'manager noon': 590, 'order': 693, 'order taxi': 695, 'taxi tomorrow': 1005, 'london': 562, 'end': 286, 'wifi airbnb': 1132, 'airbnb london': 13, 'london week': 564, 'week end': 1121, 'similar': 909, 'se': 874, 'williamsburg': 1135, 'place similar': 759, 'similar se': 911, 'se williamsburg': 876, 'nobu': 673, 'table nobu': 986, 'nobu new': 674, 'york tonight': 1152, 'guggenheim': 435, 'museum': 633, 'far guggenheim': 318, 'guggenheim museum': 436, 'know': 512, 'like know': 537, 'know galli': 513, 'galli expensive': 376, 'expensive rao': 307, 'empire': 282, 'state': 944, 'building': 109, 'empire state': 283, 'state building': 945, 'beach': 60, 'house': 470, 'toll': 1027, 'direction beach': 237, 'beach house': 61, 'house avoid': 471, 'avoid toll': 42, 'cost': 189, 'disneyland': 258, 'cost disneyland': 190, 'girl': 383, 'suppose': 960, 'send eta': 884, 'eta girl': 293, 'girl suppose': 384, 'suppose dinner': 961, 'scott': 872, 'car scott': 130, 'scott place': 873, 'wednesday': 1118, 'evening': 296, 'near london': 647, 'london hotel': 563, 'hotel wednesday': 467, 'wednesday evening': 1119, 'delmonico': 222, 'table delmonico': 975, 'yesterday': 1146, 'find restaurant': 339, 'restaurant similar': 837, 'similar go': 910, 'go yesterday': 401, 'yesterday evening': 1147, 'traffic avenue': 1042, 'avenue west': 39, 'west street': 1129, 'sunny': 958, 'go sunny': 396, 'sunny week': 959, 'shoud': 905, 'broadway': 96, 'prince': 778, 'shoud expect': 906, 'expect traffic': 301, 'traffic broadway': 1043, 'broadway prince': 97, 'prince street': 779, 'boozy': 84, 'brunch': 100, 'table boozy': 973, 'boozy brunch': 85, 'brunch nearby': 104, 'rain minute': 793, 'emily': 278, 'near emily': 642, 'emily place': 279, 'tomorrow pm': 1034, 'gate': 379, 'accident airbnb': 1, 'airbnb golden': 11, 'golden gate': 404, 'gate bridge': 380, 'itinerary': 480, 'fast itinerary': 322, 'itinerary williamsburg': 481, 'way': 1104, 'way greene': 1105, 'spot': 931, 'ippudo': 472, 'spot ippudo': 932, 'ippudo lunch': 473, 'phone': 739, 'number': 679, 'today': 1025, 'phone number': 740, 'number place': 682, 'go today': 398, 'halloween': 441, 'stop': 951, 'direction home': 241, 'home halloween': 458, 'halloween party': 442, 'party stop': 720, 'stop wine': 952, 'wine store': 1142, 'find ride': 340, 'ride hour': 851, 'weather': 1111, 'weather like': 1115, 'like work': 544, 'fine': 346, 'area': 25, 'find fine': 334, 'fine sushi': 347, 'restaurant area': 821, 'area meeting': 26, 'book uber': 80, 'uber home': 1065, 'joan': 496, 'family': 310, 'reunion': 843, 'saturday': 867, 'table joan': 983, 'joan family': 497, 'family reunion': 312, 'reunion saturday': 844, 'temperature': 1009, 'morning': 627, 'temperature tomorrow': 1010, 'tomorrow morning': 1032, 'beautiful': 62, 'day': 213, 'beautiful day': 63, 'day walk': 215, 'forecast': 351, 'rest': 818, 'weather forecast': 1112, 'forecast rest': 353, 'rest week': 819, 'reservation brunch': 807, 'brunch williamsburg': 107, 'williamsburg near': 1136, 'near bridge': 640, 'boss': 87, 'message boss': 604, 'boss eta': 88, 'starbuck': 941, 'people today': 737, 'today lunch': 1026, 'lunch starbuck': 582, 'starbuck nearby': 943, 'orleans': 696, 'forecast new': 352, 'new orleans': 670, 'jim': 491, 'share current': 897, 'location jim': 555, 'time': 1015, 'square': 934, 'near time': 654, 'time square': 1020, 'square people': 935, 'people tomorrow': 738, 'taxi near': 1003, 'near japanese': 646, 'mr': 631, 'donahue': 263, 'people mr': 733, 'mr donahue': 632, 'donahue tomorrow': 264, 'tomorrow lunch': 1031, 'estimate': 287, 'arrival': 27, 'lily': 545, 'share estimate': 898, 'estimate time': 288, 'time arrival': 1016, 'arrival lily': 29, 'congest': 188, 'road work': 855, 'work congest': 1144, 'figure': 327, 'ma': 585, 'peche': 725, 'concert': 187, 'figure reservation': 328, 'reservation ma': 812, 'ma peche': 586, 'peche concert': 726, 'menu': 600, 'menu restaurant': 601, 'restaurant book': 823, 'book tonight': 79, 'smile': 919, 'cheap place': 143, 'place galli': 751, 'galli smile': 378, 'quiet': 787, 'luck': 577, 'quiet good': 788, 'good luck': 416, 'luck bar': 578, 'road avenue': 854, 'near starbuck': 652, 'las': 524, 'vegas': 1079, 'direction las': 248, 'las vegas': 525, 'vegas avoid': 1080, 'toll road': 1028, 'airport': 15, 'ride airport': 848, 'daniel': 205, 'lunch daniel': 580, 'navigate': 635, 'palo': 703, 'alto': 17, 'navigate palo': 637, 'palo alto': 704, 'alto avoid': 18, 'valery': 1077, 'long': 565, 'to': 1023, 'join': 504, 'tell valery': 1008, 'valery long': 1078, 'long go': 566, 'go to': 397, 'to join': 1024, 'hike': 451, 'afternoon': 8, 'hike afternoon': 452, 'french': 359, 'expensive good': 304, 'good french': 411, 'french restaurant': 360, 'short': 903, 'navigate empire': 636, 'building short': 110, 'short way': 904, 'cocktail': 182, 'sister': 913, 'stay': 946, 'cheap cocktail': 141, 'cocktail bar': 183, 'bar near': 52, 'near hotel': 645, 'hotel sister': 465, 'sister stay': 914, 'right': 852, 'cab place': 122, 'place right': 757, 'like home': 535, 'home jo': 459, 'jo place': 494, 'table outside': 987, 'outside noon': 700, 'noon fry': 678, 'restaurant like': 829, 'robert': 856, 'min': 612, 'location robert': 558, 'robert min': 857, 'rand': 796, 'birthday': 70, 'photo bar': 742, 'bar go': 51, 'go rand': 395, 'rand birthday': 797, 'grand': 422, 'paramount': 707, 'soho grand': 923, 'grand well': 423, 'well paramount': 1127, 'drink': 269, 'class': 168, 'want reservation': 1101, 'reservation drink': 809, 'drink class': 270, 'class tomorrow': 169, 'italian': 478, 'table italian': 982, 'italian restaurant': 479, 'nearby dinner': 661, 'dinner people': 233, 'jfk': 489, 'direction jfk': 244, 'jfk airport': 490, 'sunday': 957, 'book restaurant': 75, 'restaurant brunch': 824, 'brunch sunday': 106, 'order cab': 694, 'cab people': 121, 'pates': 721, 'et': 289, 'tradition': 1039, 'cash': 134, 'pates et': 722, 'et tradition': 290, 'tradition cash': 1040, 'hell': 446, 'kitchen': 510, 'good irish': 413, 'pub hell': 783, 'hell kitchen': 447, 'guy': 437, 'eta guy': 295, 'guy meet': 439, 'need table': 666, 'table hour': 981, 'sophie': 927, 'red': 802, 'lobster': 546, 'table sophie': 990, 'sophie red': 928, 'red lobster': 803, 'lobster tonight': 548, 'parking': 715, 'parking hotel': 716, 'fried': 364, 'suggestion': 956, 'want eat': 1097, 'eat fried': 276, 'fried chicken': 365, 'chicken suggestion': 153, 'call': 127, 'share eta': 899, 'guy call': 438, 'crowded': 198, 'nearby crowded': 660, 'crowded tomorrow': 200, 'tomorrow evening': 1030, 'employee': 284, 'place favorite': 750, 'bar employee': 50, 'bordeaux': 86, 'like bordeaux': 534, 'reservation delmonico': 808, 'delmonico saturday': 225, 'saturday pm': 868, 'central': 137, 'traffic central': 1044, 'central park': 138, 'hillary': 453, 'location hillary': 554, 'hillary sister': 454, 'upcoming': 1070, 'trip': 1056, 'los': 569, 'angeles': 21, 'forecast upcoming': 354, 'upcoming trip': 1073, 'trip los': 1057, 'los angeles': 570, 'traffic meet': 1048, 'meet friend': 596, 'friend tonight': 369, 'boston': 89, 'like new': 541, 'york boston': 1151, 'romantic': 860, 'serve': 887, 'girlfriend': 385, 'find romantic': 341, 'romantic restaurant': 861, 'restaurant serve': 836, 'serve good': 889, 'expensive wine': 309, 'wine near': 1141, 'near girlfriend': 643, 'girlfriend work': 386, 'sebastian': 879, 'book taxi': 78, 'taxi sebastian': 1004, 'brooklyn': 98, 'jam brooklyn': 484, 'brooklyn bridge': 99, 'direction meeting': 249, 'meeting avoid': 598, 'coffee': 185, 'gluten': 389, 'free': 357, 'find coffee': 332, 'coffee place': 186, 'similar starbuck': 912, 'starbuck gluten': 942, 'gluten free': 390, 'free food': 358, 'american': 19, 'thanksgive': 1011, 'table american': 972, 'american restaurant': 20, 'restaurant thanksgive': 838, 'attraction': 32, 'hollywood': 455, 'angie': 22, 'find family': 333, 'family attraction': 311, 'attraction hollywood': 33, 'hollywood far': 456, 'far angie': 316, 'angie place': 23, 'view': 1085, 'reserve': 816, 'view reserve': 1087, 'reserve parking': 817, 'host': 461, 'share time': 902, 'arrival airbnb': 28, 'airbnb host': 12, 'child': 154, 'standard': 937, 'grill': 427, 'child menu': 156, 'menu standard': 602, 'standard grill': 938, 'place near': 755, 'near chelsea': 641, 'chelsea good': 147, 'good brunch': 406, 'brunch cocktail': 101, 'cocktail tomorrow': 184, 'swan': 967, 'oyster': 701, 'depot': 226, 'swan oyster': 968, 'oyster depot': 702, 'depot cash': 227, 'direction hotel': 242, 'traffic hotel': 1045, 'driver': 273, 'location uber': 560, 'uber driver': 1064, 'need weather': 668, 'weather jo': 1114, 'place pm': 756, 'book ride': 76, 'ride current': 850, 'like london': 539, 'nyc': 683, 'chicago': 149, 'hotel nyc': 464, 'nyc week': 684, 'week well': 1122, 'well hotel': 1126, 'hotel stay': 466, 'stay chicago': 947, 'data': 208, 'scientist': 871, 'eta data': 292, 'data scientist': 209, 'way work': 1109, 'moma': 618, 'direction moma': 251, 'send location': 885, 'grab': 420, 'reservation grab': 810, 'grab brunch': 421, 'brunch hell': 103, 'kitchen tomorrow': 511, 'expensive restaurant': 308, 'restaurant se': 835, 'se rao': 875, 'fast way': 323, 'way meeting': 1107, 'juan': 506, 'carlos': 133, 'share arrival': 896, 'arrival time': 31, 'time juan': 1018, 'juan carlos': 507, 'accident home': 3, 'home work': 460, 'quick': 784, 'want boston': 1096, 'boston quick': 90, 'quick itinerary': 786, 'monday': 619, 'delmonico monday': 224, 'monday pm': 620, 'butcher': 115, 'daughter': 210, 'butcher daughter': 116, 'daughter menu': 211, 'yoga': 1148, 'retreat': 841, 'highway': 450, 'direction yoga': 257, 'yoga retreat': 1149, 'retreat avoid': 842, 'avoid highway': 41, 'din': 228, 'tai': 992, 'fung': 373, 'december': 218, 'table din': 976, 'din tai': 229, 'tai fung': 993, 'fung december': 374, 'umbrella walk': 1069, 'walk dinner': 1091, 'tapestry': 994, 'people tapestry': 736, 'tapestry pm': 995, 'pm tonight': 768, 'land': 522, 'paris': 710, 'like land': 538, 'land paris': 523, 'steve': 948, 'location steve': 559, 'steve day': 950, 'activity': 4, 'hard': 443, 'rock': 858, 'activity child': 5, 'child hard': 155, 'hard rock': 444, 'rock cafe': 859, 'weather good': 1113, 'good walk': 419, 'walk today': 1094, 'irving': 476, 'plaza': 763, 'locate': 549, 'irving plaza': 477, 'plaza locate': 764, 'crowded bar': 199, 'near place': 650, 'delmonico evening': 223, 'evening pm': 297, 'dead': 216, 'rabbit': 790, 'number dead': 680, 'dead rabbit': 217, 'like jo': 536, 'place afternoon': 747, 'problem': 780, 'traffic problem': 1050, 'problem dinner': 781, 'bicycle': 68, 'millenium': 610, 'bicycle direction': 69, 'direction millenium': 250, 'millenium park': 611, 'county': 191, 'santa': 865, 'monica': 623, 'direction la': 247, 'la county': 518, 'county museum': 192, 'museum santa': 634, 'santa monica': 866, 'shake': 893, 'shack': 891, 'cab shake': 123, 'shake shack': 894, 'shack empire': 892, 'parent': 708, 'direction parent': 252, 'parent place': 709, 'place avoid': 748, 'windy': 1137, 'windy tomorrow': 1138, 'tell friend': 1007, 'friend time': 368, 'rain right': 794, 'gym': 440, 'traffic work': 1053, 'work gym': 1145, 'mother': 629, 'stadium': 936, 'cab mother': 120, 'mother place': 630, 'place la': 753, 'la stadium': 520, 'old': 687, 'sauce': 869, 'joint': 505, 'want find': 1098, 'find reservation': 338, 'reservation old': 813, 'old red': 688, 'red sauce': 804, 'sauce joint': 870, 'pour': 773, 'ribbon': 845, 'open': 689, 'time pour': 1019, 'pour ribbon': 774, 'ribbon open': 846, 'open tonight': 690, 'guardia': 431, 'waze': 1110, 'la guardia': 519, 'guardia airport': 432, 'airport waze': 16, 'catch': 135, 'flight': 348, 'taxi catch': 1000, 'catch flight': 136, 'flight tomorrow': 349, 'arrival mother': 30, 'sell': 880, 'burritos': 113, 'south': 929, 'harlem': 445, 'find place': 337, 'place sell': 758, 'sell burritos': 881, 'burritos south': 114, 'south harlem': 930, 'price': 776, 'range': 798, 'price range': 777, 'range dinner': 799, 'dinner galli': 231, 'father': 324, 'location father': 552, 'pay': 723, 'credit': 195, 'card': 131, 'boom': 81, 'room': 862, 'pay credit': 724, 'credit card': 196, 'card boom': 132, 'boom boom': 82, 'boom room': 83, 'address': 6, 'manhattan': 591, 'steve address': 949, 'address manhattan': 7, 'balthazar': 47, 'lombardi': 561, 'restaurant balthazar': 822, 'balthazar lombardi': 48, 'montgomery': 624, 'message montgomery': 607, 'montgomery arrival': 625, 'restaurant manhattan': 831, 'tip': 1021, 'modern': 617, 'good tip': 418, 'tip know': 1022, 'know go': 514, 'go modern': 393, 'guest': 433, 'apartment': 24, 'eta guest': 294, 'guest apartment': 434, 'joe': 498, 'direction joe': 245, 'joe pub': 499, 'location jo': 556, 'jo pm': 495, 'star': 939, 'find star': 342, 'star restaurant': 940, 'restaurant los': 830, 'want know': 1099, 'know traffic': 515, 'traffic upcoming': 1051, 'upcoming meeting': 1072, 'table standard': 991, 'grill people': 428, 'people day': 728, 'day tomorrow': 214, 'event': 298, 'like near': 540, 'near upcoming': 656, 'upcoming event': 1071, 'mondrian': 621, 'people mondrian': 732, 'mondrian soho': 622, 'soho pm': 924, 'want weather': 1103, 'weather paris': 1116, 'way rand': 1108, 'birthday party': 71, 'party car': 718, 'pan': 705, 'highline': 448, 'ballroom': 46, 'far fry': 317, 'fry pan': 372, 'pan highline': 706, 'highline ballroom': 449, 'month': 626, 'number hotel': 681, 'hotel chicago': 463, 'chicago month': 150, 'people la': 731, 'chine pm': 158, 'uber meeting': 1066, 'weekend': 1123, 'upcoming weekend': 1074, 'time employee': 1017, 'employee close': 285, 'wifi smile': 1134, 'jersey': 487, 'city': 165, 'direction jersey': 243, 'jersey city': 488, 'city avoid': 166, 'franz': 355, 'share franz': 900, 'franz eta': 356, 'le': 526, 'bain': 44, 'marquee': 593, 'good le': 415, 'le bain': 527, 'bain marquee': 45, 'chop': 161, 'table chop': 974, 'chop lobster': 162, 'lobster bar': 547, 'bar people': 53, 'traffic jo': 1047, 'book cab': 73, 'walk meeting': 1093, 'like pm': 543, 'pm central': 766, 'breakfast': 93, 'batter': 58, 'berry': 66, 'reservation breakfast': 806, 'breakfast batter': 94, 'batter berry': 59, 'berry tomorrow': 67, 'chinese': 159, 'town': 1037, 'good chinese': 408, 'chinese restaurant': 160, 'restaurant town': 839, 'town today': 1038, 'good restaurant': 417, 'airbnb serve': 14, 'serve brunch': 888, 'brunch day': 102, 'buffet': 108, 'close restaurant': 176, 'restaurant eat': 826, 'eat buffet': 275, 'pick': 744, 'son': 925, 'soccer': 920, 'practice': 775, 'quick direction': 785, 'direction pick': 253, 'pick son': 745, 'son soccer': 926, 'soccer practice': 921, 'near morning': 649, 'morning meeting': 628, 'meeting tomorrow': 599, 'coat': 180, 'rain coat': 792, 'coat today': 181, 'masa': 594, 'view expensive': 1086, 'expensive masa': 306, 'audrey': 34, 'sam': 863, 'wedding': 1117, 'taxi audrey': 999, 'audrey sam': 35, 'sam wedding': 864, 'vegetarian': 1081, 'daughter serve': 212, 'serve vegetarian': 890, 'vegetarian food': 1082, 'fancy': 313, 'club': 178, 'fancy club': 314, 'club new': 179, 'traffic way': 1052, 'way gym': 1106, 'low': 575, 'find brunch': 330, 'brunch spot': 105, 'spot low': 933, 'low manhattan': 576}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer_spacy.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d95e24-c5d3-474a-ae02-4b079da7f7df",
   "metadata": {},
   "source": [
    "To get all the words in order use the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8634f8e0-5f47-4689-a6ca-8372eb6204c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feature_names = vectorizer_spacy.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f2ceda-5ac2-4e4f-abfa-f24275320e80",
   "metadata": {},
   "source": [
    "To get the tfidf score for all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3be81991-cd8f-4af8-ab15-7b87fe1c250d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accident 5.185859671057874\n",
      "accident airbnb 5.879006851617819\n",
      "accident expect 5.879006851617819\n",
      "accident home 5.879006851617819\n",
      "activity 5.879006851617819\n",
      "activity child 5.879006851617819\n",
      "address 5.879006851617819\n",
      "address manhattan 5.879006851617819\n",
      "afternoon 5.473541743509655\n",
      "airbnb 4.626243883122451\n",
      "airbnb close 5.879006851617819\n",
      "airbnb golden 5.879006851617819\n",
      "airbnb host 5.879006851617819\n",
      "airbnb london 5.879006851617819\n",
      "airbnb serve 5.879006851617819\n",
      "airport 5.185859671057874\n",
      "airport waze 5.879006851617819\n",
      "alto 5.879006851617819\n",
      "alto avoid 5.879006851617819\n",
      "american 5.879006851617819\n",
      "american restaurant 5.879006851617819\n",
      "angeles 5.473541743509655\n",
      "angie 5.879006851617819\n",
      "angie place 5.879006851617819\n",
      "apartment 5.879006851617819\n",
      "area 5.879006851617819\n",
      "area meeting 5.879006851617819\n",
      "arrival 4.780394562949709\n",
      "arrival airbnb 5.879006851617819\n",
      "arrival lily 5.879006851617819\n",
      "arrival mother 5.879006851617819\n",
      "arrival time 5.473541743509655\n",
      "attraction 5.879006851617819\n",
      "attraction hollywood 5.879006851617819\n",
      "audrey 5.879006851617819\n",
      "audrey sam 5.879006851617819\n",
      "aunt 5.879006851617819\n",
      "aunt place 5.879006851617819\n",
      "avenue 4.962716119743664\n",
      "avenue west 5.879006851617819\n",
      "avoid 4.374929454841546\n",
      "avoid highway 5.473541743509655\n",
      "avoid toll 5.185859671057874\n",
      "avoid traffic 5.185859671057874\n",
      "bain 5.879006851617819\n",
      "bain marquee 5.879006851617819\n",
      "ballroom 5.879006851617819\n",
      "balthazar 5.879006851617819\n",
      "balthazar lombardi 5.879006851617819\n",
      "bar 4.174258759379394\n",
      "bar employee 5.879006851617819\n",
      "bar go 5.879006851617819\n",
      "bar near 5.473541743509655\n",
      "bar people 5.879006851617819\n",
      "bar usually 5.879006851617819\n",
      "bar well 5.879006851617819\n",
      "barcelona 5.879006851617819\n",
      "barcelona wine 5.879006851617819\n",
      "batter 5.879006851617819\n",
      "batter berry 5.879006851617819\n",
      "beach 5.879006851617819\n",
      "beach house 5.879006851617819\n",
      "beautiful 5.879006851617819\n",
      "beautiful day 5.879006851617819\n",
      "belasco 5.879006851617819\n",
      "belasco theatre 5.879006851617819\n",
      "berry 5.879006851617819\n",
      "berry tomorrow 5.879006851617819\n",
      "bicycle 5.879006851617819\n",
      "bicycle direction 5.879006851617819\n",
      "birthday 5.473541743509655\n",
      "birthday party 5.879006851617819\n",
      "book 3.106418129378038\n",
      "book cab 5.879006851617819\n",
      "book lyft 5.879006851617819\n",
      "book restaurant 5.473541743509655\n",
      "book ride 5.879006851617819\n",
      "book table 3.436659816248615\n",
      "book taxi 5.879006851617819\n",
      "book tonight 5.879006851617819\n",
      "book uber 5.473541743509655\n",
      "boom 5.879006851617819\n",
      "boom boom 5.879006851617819\n",
      "boom room 5.879006851617819\n",
      "boozy 5.879006851617819\n",
      "boozy brunch 5.879006851617819\n",
      "bordeaux 5.879006851617819\n",
      "boss 5.879006851617819\n",
      "boss eta 5.879006851617819\n",
      "boston 5.473541743509655\n",
      "boston quick 5.879006851617819\n",
      "boyfriend 5.879006851617819\n",
      "boyfriend home 5.879006851617819\n",
      "breakfast 5.879006851617819\n",
      "breakfast batter 5.879006851617819\n",
      "bridge 4.962716119743664\n",
      "broadway 5.879006851617819\n",
      "broadway prince 5.879006851617819\n",
      "brooklyn 5.879006851617819\n",
      "brooklyn bridge 5.879006851617819\n",
      "brunch 4.4927124904979285\n",
      "brunch cocktail 5.879006851617819\n",
      "brunch day 5.879006851617819\n",
      "brunch hell 5.879006851617819\n",
      "brunch nearby 5.879006851617819\n",
      "brunch spot 5.879006851617819\n",
      "brunch sunday 5.879006851617819\n",
      "brunch williamsburg 5.879006851617819\n",
      "buffet 5.879006851617819\n",
      "building 5.185859671057874\n",
      "building short 5.879006851617819\n",
      "burger 5.879006851617819\n",
      "burger soho 5.879006851617819\n",
      "burritos 5.879006851617819\n",
      "burritos south 5.879006851617819\n",
      "butcher 5.473541743509655\n",
      "butcher daughter 5.473541743509655\n",
      "buy 5.879006851617819\n",
      "buy champagne 5.879006851617819\n",
      "cab 4.626243883122451\n",
      "cab mother 5.879006851617819\n",
      "cab people 5.879006851617819\n",
      "cab place 5.879006851617819\n",
      "cab shake 5.879006851617819\n",
      "cab work 5.879006851617819\n",
      "cafe 5.473541743509655\n",
      "cafe gitane 5.879006851617819\n",
      "call 5.879006851617819\n",
      "car 5.185859671057874\n",
      "car greene 5.879006851617819\n",
      "car scott 5.879006851617819\n",
      "card 5.879006851617819\n",
      "card boom 5.879006851617819\n",
      "carlos 5.879006851617819\n",
      "cash 5.473541743509655\n",
      "catch 5.879006851617819\n",
      "catch flight 5.879006851617819\n",
      "central 5.473541743509655\n",
      "central park 5.473541743509655\n",
      "champagne 5.879006851617819\n",
      "cheap 4.4927124904979285\n",
      "cheap cocktail 5.879006851617819\n",
      "cheap lose 5.879006851617819\n",
      "cheap place 5.473541743509655\n",
      "cheap restaurant 5.473541743509655\n",
      "cheap seafood 5.879006851617819\n",
      "chelsea 5.473541743509655\n",
      "chelsea good 5.879006851617819\n",
      "chelsea market 5.879006851617819\n",
      "chicago 5.473541743509655\n",
      "chicago month 5.879006851617819\n",
      "chicken 5.185859671057874\n",
      "chicken restaurant 5.473541743509655\n",
      "chicken suggestion 5.879006851617819\n",
      "child 5.473541743509655\n",
      "child hard 5.879006851617819\n",
      "child menu 5.879006851617819\n",
      "chine 5.473541743509655\n",
      "chine pm 5.879006851617819\n",
      "chinese 5.879006851617819\n",
      "chinese restaurant 5.879006851617819\n",
      "chop 5.879006851617819\n",
      "chop lobster 5.879006851617819\n",
      "christmas 5.879006851617819\n",
      "christmas party 5.879006851617819\n",
      "city 5.879006851617819\n",
      "city avoid 5.879006851617819\n",
      "citymapper 5.879006851617819\n",
      "class 5.879006851617819\n",
      "class tomorrow 5.879006851617819\n",
      "client 5.879006851617819\n",
      "client meeting 5.879006851617819\n",
      "close 4.626243883122451\n",
      "close hotel 5.879006851617819\n",
      "close jo 5.879006851617819\n",
      "close john 5.879006851617819\n",
      "close restaurant 5.879006851617819\n",
      "close theatre 5.879006851617819\n",
      "club 5.879006851617819\n",
      "club new 5.879006851617819\n",
      "coat 5.879006851617819\n",
      "coat today 5.879006851617819\n",
      "cocktail 5.473541743509655\n",
      "cocktail bar 5.879006851617819\n",
      "cocktail tomorrow 5.879006851617819\n",
      "coffee 5.879006851617819\n",
      "coffee place 5.879006851617819\n",
      "concert 5.879006851617819\n",
      "congest 5.879006851617819\n",
      "cost 5.879006851617819\n",
      "cost disneyland 5.879006851617819\n",
      "county 5.879006851617819\n",
      "county museum 5.879006851617819\n",
      "cousin 5.879006851617819\n",
      "cousin place 5.879006851617819\n",
      "credit 5.879006851617819\n",
      "credit card 5.879006851617819\n",
      "crowd 5.879006851617819\n",
      "crowded 5.473541743509655\n",
      "crowded bar 5.879006851617819\n",
      "crowded tomorrow 5.879006851617819\n",
      "current 4.780394562949709\n",
      "current location 4.780394562949709\n",
      "cycling 5.473541743509655\n",
      "cycling direction 5.473541743509655\n",
      "daniel 5.879006851617819\n",
      "dash 5.879006851617819\n",
      "dash cheap 5.879006851617819\n",
      "data 5.879006851617819\n",
      "data scientist 5.879006851617819\n",
      "daughter 5.473541743509655\n",
      "daughter menu 5.879006851617819\n",
      "daughter serve 5.879006851617819\n",
      "day 4.962716119743664\n",
      "day tomorrow 5.879006851617819\n",
      "day walk 5.879006851617819\n",
      "dead 5.879006851617819\n",
      "dead rabbit 5.879006851617819\n",
      "december 5.879006851617819\n",
      "deli 5.879006851617819\n",
      "deli near 5.879006851617819\n",
      "delicatessen 5.473541743509655\n",
      "delmonico 4.962716119743664\n",
      "delmonico evening 5.879006851617819\n",
      "delmonico monday 5.879006851617819\n",
      "delmonico saturday 5.879006851617819\n",
      "depot 5.879006851617819\n",
      "depot cash 5.879006851617819\n",
      "din 5.879006851617819\n",
      "din tai 5.879006851617819\n",
      "dinner 4.374929454841546\n",
      "dinner galli 5.879006851617819\n",
      "dinner la 5.879006851617819\n",
      "dinner people 5.879006851617819\n",
      "dinner tonight 5.473541743509655\n",
      "direction 3.394100201829819\n",
      "direction barcelona 5.879006851617819\n",
      "direction beach 5.879006851617819\n",
      "direction chelsea 5.879006851617819\n",
      "direction christmas 5.879006851617819\n",
      "direction disneyworld 5.879006851617819\n",
      "direction home 5.879006851617819\n",
      "direction hotel 5.879006851617819\n",
      "direction jersey 5.879006851617819\n",
      "direction jfk 5.879006851617819\n",
      "direction joe 5.879006851617819\n",
      "direction john 5.879006851617819\n",
      "direction la 5.473541743509655\n",
      "direction las 5.879006851617819\n",
      "direction meeting 5.879006851617819\n",
      "direction millenium 5.879006851617819\n",
      "direction moma 5.879006851617819\n",
      "direction parent 5.879006851617819\n",
      "direction pick 5.879006851617819\n",
      "direction surf 5.879006851617819\n",
      "direction tavern 5.879006851617819\n",
      "direction tulsa 5.879006851617819\n",
      "direction yoga 5.879006851617819\n",
      "disneyland 5.879006851617819\n",
      "disneyworld 5.879006851617819\n",
      "disneyworld avoid 5.879006851617819\n",
      "dolore 5.879006851617819\n",
      "dolore park 5.879006851617819\n",
      "donahue 5.879006851617819\n",
      "donahue tomorrow 5.879006851617819\n",
      "donut 5.879006851617819\n",
      "donut pub 5.879006851617819\n",
      "dot 5.879006851617819\n",
      "dot dash 5.879006851617819\n",
      "drink 5.879006851617819\n",
      "drink class 5.879006851617819\n",
      "drive 5.879006851617819\n",
      "drive direction 5.879006851617819\n",
      "driver 5.879006851617819\n",
      "eat 5.185859671057874\n",
      "eat buffet 5.879006851617819\n",
      "eat fried 5.879006851617819\n",
      "eat good 5.879006851617819\n",
      "emily 5.879006851617819\n",
      "emily place 5.879006851617819\n",
      "emmit 5.879006851617819\n",
      "emmit irish 5.879006851617819\n",
      "empire 5.185859671057874\n",
      "empire state 5.185859671057874\n",
      "employee 5.473541743509655\n",
      "employee close 5.879006851617819\n",
      "end 5.879006851617819\n",
      "estimate 5.473541743509655\n",
      "estimate time 5.473541743509655\n",
      "et 5.879006851617819\n",
      "et tradition 5.879006851617819\n",
      "eta 4.269568939183719\n",
      "eta data 5.879006851617819\n",
      "eta girl 5.879006851617819\n",
      "eta guest 5.879006851617819\n",
      "eta guy 5.473541743509655\n",
      "evening 4.962716119743664\n",
      "evening pm 5.879006851617819\n",
      "event 5.879006851617819\n",
      "expect 5.185859671057874\n",
      "expect cousin 5.879006851617819\n",
      "expect traffic 5.473541743509655\n",
      "expensive 4.4927124904979285\n",
      "expensive bar 5.879006851617819\n",
      "expensive good 5.879006851617819\n",
      "expensive japanese 5.879006851617819\n",
      "expensive masa 5.879006851617819\n",
      "expensive rao 5.879006851617819\n",
      "expensive restaurant 5.879006851617819\n",
      "expensive wine 5.879006851617819\n",
      "family 5.473541743509655\n",
      "family attraction 5.879006851617819\n",
      "family reunion 5.879006851617819\n",
      "fancy 5.879006851617819\n",
      "fancy club 5.879006851617819\n",
      "far 4.962716119743664\n",
      "far angie 5.879006851617819\n",
      "far fry 5.879006851617819\n",
      "far guggenheim 5.879006851617819\n",
      "far nomad 5.879006851617819\n",
      "fast 5.185859671057874\n",
      "fast food 5.879006851617819\n",
      "fast itinerary 5.879006851617819\n",
      "fast way 5.879006851617819\n",
      "father 5.879006851617819\n",
      "favorite 5.473541743509655\n",
      "favorite bar 5.473541743509655\n",
      "figure 5.879006851617819\n",
      "figure reservation 5.879006851617819\n",
      "find 3.627715053011324\n",
      "find brunch 5.879006851617819\n",
      "find cheap 5.879006851617819\n",
      "find coffee 5.879006851617819\n",
      "find family 5.879006851617819\n",
      "find fine 5.879006851617819\n",
      "find good 5.185859671057874\n",
      "find outdoor 5.879006851617819\n",
      "find place 5.879006851617819\n",
      "find reservation 5.879006851617819\n",
      "find restaurant 5.879006851617819\n",
      "find ride 5.879006851617819\n",
      "find romantic 5.879006851617819\n",
      "find star 5.879006851617819\n",
      "find store 5.879006851617819\n",
      "find table 5.879006851617819\n",
      "find taxi 5.879006851617819\n",
      "fine 5.879006851617819\n",
      "fine sushi 5.879006851617819\n",
      "flight 5.879006851617819\n",
      "flight tomorrow 5.879006851617819\n",
      "food 5.185859671057874\n",
      "forecast 4.962716119743664\n",
      "forecast new 5.879006851617819\n",
      "forecast rest 5.879006851617819\n",
      "forecast upcoming 5.473541743509655\n",
      "franz 5.879006851617819\n",
      "franz eta 5.879006851617819\n",
      "free 5.879006851617819\n",
      "free food 5.879006851617819\n",
      "french 5.473541743509655\n",
      "french restaurant 5.473541743509655\n",
      "friday 5.185859671057874\n",
      "friday night 5.879006851617819\n",
      "friday pm 5.473541743509655\n",
      "fried 5.879006851617819\n",
      "fried chicken 5.879006851617819\n",
      "friend 5.185859671057874\n",
      "friend meet 5.879006851617819\n",
      "friend time 5.879006851617819\n",
      "friend tonight 5.879006851617819\n",
      "fry 5.185859671057874\n",
      "fry chicken 5.473541743509655\n",
      "fry pan 5.879006851617819\n",
      "fung 5.879006851617819\n",
      "fung december 5.879006851617819\n",
      "galli 4.962716119743664\n",
      "galli expensive 5.879006851617819\n",
      "galli friday 5.879006851617819\n",
      "galli smile 5.879006851617819\n",
      "gate 5.879006851617819\n",
      "gate bridge 5.879006851617819\n",
      "gershwin 5.879006851617819\n",
      "gershwin theatre 5.879006851617819\n",
      "girl 5.879006851617819\n",
      "girl suppose 5.879006851617819\n",
      "girlfriend 5.879006851617819\n",
      "girlfriend work 5.879006851617819\n",
      "gitane 5.879006851617819\n",
      "gitane wifi 5.879006851617819\n",
      "gluten 5.879006851617819\n",
      "gluten free 5.879006851617819\n",
      "go 4.087247382389764\n",
      "go client 5.879006851617819\n",
      "go modern 5.879006851617819\n",
      "go rain 5.879006851617819\n",
      "go rand 5.879006851617819\n",
      "go sunny 5.879006851617819\n",
      "go to 5.879006851617819\n",
      "go today 5.879006851617819\n",
      "go tonight 5.879006851617819\n",
      "go week 5.473541743509655\n",
      "go yesterday 5.879006851617819\n",
      "golden 5.473541743509655\n",
      "golden bridge 5.879006851617819\n",
      "golden gate 5.879006851617819\n",
      "good 3.799565309937983\n",
      "good brunch 5.879006851617819\n",
      "good burger 5.879006851617819\n",
      "good chinese 5.879006851617819\n",
      "good deli 5.879006851617819\n",
      "good expensive 5.473541743509655\n",
      "good french 5.879006851617819\n",
      "good fry 5.879006851617819\n",
      "good irish 5.879006851617819\n",
      "good japanese 5.879006851617819\n",
      "good le 5.879006851617819\n",
      "good luck 5.879006851617819\n",
      "good restaurant 5.879006851617819\n",
      "good tip 5.879006851617819\n",
      "good walk 5.879006851617819\n",
      "grab 5.879006851617819\n",
      "grab brunch 5.879006851617819\n",
      "grand 5.879006851617819\n",
      "grand well 5.879006851617819\n",
      "green 5.879006851617819\n",
      "greene 5.473541743509655\n",
      "greene street 5.473541743509655\n",
      "grill 5.473541743509655\n",
      "grill people 5.879006851617819\n",
      "group 5.879006851617819\n",
      "group near 5.879006851617819\n",
      "guardia 5.879006851617819\n",
      "guardia airport 5.879006851617819\n",
      "guest 5.879006851617819\n",
      "guest apartment 5.879006851617819\n",
      "guggenheim 5.879006851617819\n",
      "guggenheim museum 5.879006851617819\n",
      "guy 5.473541743509655\n",
      "guy call 5.879006851617819\n",
      "guy meet 5.879006851617819\n",
      "gym 5.473541743509655\n",
      "halloween 5.879006851617819\n",
      "halloween party 5.879006851617819\n",
      "hard 5.879006851617819\n",
      "hard rock 5.879006851617819\n",
      "harlem 5.879006851617819\n",
      "hell 5.473541743509655\n",
      "hell kitchen 5.473541743509655\n",
      "highline 5.879006851617819\n",
      "highline ballroom 5.879006851617819\n",
      "highway 5.473541743509655\n",
      "hike 5.879006851617819\n",
      "hike afternoon 5.879006851617819\n",
      "hillary 5.879006851617819\n",
      "hillary sister 5.879006851617819\n",
      "hollywood 5.879006851617819\n",
      "hollywood far 5.879006851617819\n",
      "home 4.626243883122451\n",
      "home halloween 5.879006851617819\n",
      "home jo 5.879006851617819\n",
      "home work 5.879006851617819\n",
      "host 5.879006851617819\n",
      "hotel 4.269568939183719\n",
      "hotel chicago 5.879006851617819\n",
      "hotel nyc 5.879006851617819\n",
      "hotel sister 5.879006851617819\n",
      "hotel stay 5.879006851617819\n",
      "hotel wednesday 5.879006851617819\n",
      "hour 5.185859671057874\n",
      "hour tell 5.879006851617819\n",
      "house 5.879006851617819\n",
      "house avoid 5.879006851617819\n",
      "ippudo 5.879006851617819\n",
      "ippudo lunch 5.879006851617819\n",
      "irish 5.473541743509655\n",
      "irish pub 5.473541743509655\n",
      "irving 5.879006851617819\n",
      "irving plaza 5.879006851617819\n",
      "italian 5.879006851617819\n",
      "italian restaurant 5.879006851617819\n",
      "itinerary 5.473541743509655\n",
      "itinerary williamsburg 5.879006851617819\n",
      "jam 5.473541743509655\n",
      "jam avenue 5.879006851617819\n",
      "jam brooklyn 5.879006851617819\n",
      "japanese 5.185859671057874\n",
      "japanese restaurant 5.185859671057874\n",
      "jersey 5.879006851617819\n",
      "jersey city 5.879006851617819\n",
      "jfk 5.879006851617819\n",
      "jfk airport 5.879006851617819\n",
      "jim 5.879006851617819\n",
      "jo 4.626243883122451\n",
      "jo lori 5.879006851617819\n",
      "jo place 4.962716119743664\n",
      "jo pm 5.879006851617819\n",
      "joan 5.879006851617819\n",
      "joan family 5.879006851617819\n",
      "joe 5.879006851617819\n",
      "joe pub 5.879006851617819\n",
      "john 5.185859671057874\n",
      "john hotel 5.879006851617819\n",
      "john place 5.879006851617819\n",
      "john tell 5.879006851617819\n",
      "join 5.879006851617819\n",
      "joint 5.879006851617819\n",
      "juan 5.879006851617819\n",
      "juan carlos 5.879006851617819\n",
      "katz 5.473541743509655\n",
      "katz delicatessen 5.473541743509655\n",
      "kitchen 5.473541743509655\n",
      "kitchen tomorrow 5.879006851617819\n",
      "know 5.185859671057874\n",
      "know galli 5.879006851617819\n",
      "know go 5.879006851617819\n",
      "know traffic 5.879006851617819\n",
      "la 4.780394562949709\n",
      "la chine 5.473541743509655\n",
      "la county 5.879006851617819\n",
      "la guardia 5.879006851617819\n",
      "la stadium 5.879006851617819\n",
      "lake 5.879006851617819\n",
      "land 5.879006851617819\n",
      "land paris 5.879006851617819\n",
      "las 5.879006851617819\n",
      "las vegas 5.879006851617819\n",
      "le 5.879006851617819\n",
      "le bain 5.879006851617819\n",
      "leave 5.473541743509655\n",
      "leave pm 5.879006851617819\n",
      "lebanese 5.879006851617819\n",
      "lebanese restaurant 5.879006851617819\n",
      "lesson 5.879006851617819\n",
      "like 4.0072046747162275\n",
      "like bordeaux 5.879006851617819\n",
      "like home 5.879006851617819\n",
      "like jo 5.879006851617819\n",
      "like know 5.879006851617819\n",
      "like land 5.879006851617819\n",
      "like london 5.879006851617819\n",
      "like near 5.879006851617819\n",
      "like new 5.879006851617819\n",
      "like outside 5.879006851617819\n",
      "like pm 5.879006851617819\n",
      "like work 5.879006851617819\n",
      "lily 5.879006851617819\n",
      "lobster 5.473541743509655\n",
      "lobster bar 5.879006851617819\n",
      "lobster tonight 5.879006851617819\n",
      "locate 5.879006851617819\n",
      "location 3.933096702562506\n",
      "location boyfriend 5.879006851617819\n",
      "location father 5.879006851617819\n",
      "location friend 5.879006851617819\n",
      "location hillary 5.879006851617819\n",
      "location jim 5.879006851617819\n",
      "location jo 5.879006851617819\n",
      "location office 5.879006851617819\n",
      "location robert 5.879006851617819\n",
      "location steve 5.879006851617819\n",
      "location uber 5.879006851617819\n",
      "lombardi 5.879006851617819\n",
      "london 5.185859671057874\n",
      "london hotel 5.879006851617819\n",
      "london week 5.473541743509655\n",
      "long 5.879006851617819\n",
      "long go 5.879006851617819\n",
      "lori 5.879006851617819\n",
      "lori place 5.879006851617819\n",
      "los 5.473541743509655\n",
      "los angeles 5.473541743509655\n",
      "lose 5.879006851617819\n",
      "lose lake 5.879006851617819\n",
      "lounge 5.879006851617819\n",
      "lounge expensive 5.879006851617819\n",
      "low 5.879006851617819\n",
      "low manhattan 5.879006851617819\n",
      "luck 5.879006851617819\n",
      "luck bar 5.879006851617819\n",
      "lunch 4.4927124904979285\n",
      "lunch daniel 5.879006851617819\n",
      "lunch party 5.879006851617819\n",
      "lunch starbuck 5.879006851617819\n",
      "lyft 5.473541743509655\n",
      "lyft car 5.473541743509655\n",
      "ma 5.879006851617819\n",
      "ma peche 5.879006851617819\n",
      "majestic 5.879006851617819\n",
      "majestic theatre 5.879006851617819\n",
      "manager 5.879006851617819\n",
      "manager noon 5.879006851617819\n",
      "manhattan 5.185859671057874\n",
      "market 5.879006851617819\n",
      "marquee 5.879006851617819\n",
      "masa 5.879006851617819\n",
      "meet 5.185859671057874\n",
      "meet friend 5.879006851617819\n",
      "meeting 4.374929454841546\n",
      "meeting avoid 5.879006851617819\n",
      "meeting tomorrow 5.879006851617819\n",
      "menu 5.185859671057874\n",
      "menu restaurant 5.879006851617819\n",
      "menu standard 5.879006851617819\n",
      "message 4.962716119743664\n",
      "message boss 5.879006851617819\n",
      "message john 5.879006851617819\n",
      "message michael 5.879006851617819\n",
      "message montgomery 5.879006851617819\n",
      "michael 5.879006851617819\n",
      "michael eta 5.879006851617819\n",
      "millenium 5.879006851617819\n",
      "millenium park 5.879006851617819\n",
      "min 5.879006851617819\n",
      "minute 5.473541743509655\n",
      "minute avenue 5.879006851617819\n",
      "mission 5.879006851617819\n",
      "mission dolore 5.879006851617819\n",
      "modern 5.879006851617819\n",
      "moma 5.879006851617819\n",
      "monday 5.879006851617819\n",
      "monday pm 5.879006851617819\n",
      "mondrian 5.879006851617819\n",
      "mondrian soho 5.879006851617819\n",
      "monica 5.879006851617819\n",
      "montgomery 5.879006851617819\n",
      "montgomery arrival 5.879006851617819\n",
      "month 5.879006851617819\n",
      "morning 5.185859671057874\n",
      "morning meeting 5.879006851617819\n",
      "mother 5.473541743509655\n",
      "mother place 5.879006851617819\n",
      "mr 5.879006851617819\n",
      "mr donahue 5.879006851617819\n",
      "museum 5.473541743509655\n",
      "museum santa 5.879006851617819\n",
      "navigate 5.473541743509655\n",
      "navigate empire 5.879006851617819\n",
      "navigate palo 5.879006851617819\n",
      "near 3.394100201829819\n",
      "near airbnb 5.473541743509655\n",
      "near bridge 5.879006851617819\n",
      "near chelsea 5.879006851617819\n",
      "near emily 5.879006851617819\n",
      "near girlfriend 5.879006851617819\n",
      "near golden 5.879006851617819\n",
      "near hotel 5.879006851617819\n",
      "near japanese 5.879006851617819\n",
      "near london 5.879006851617819\n",
      "near mission 5.879006851617819\n",
      "near morning 5.879006851617819\n",
      "near place 5.879006851617819\n",
      "near sia 5.879006851617819\n",
      "near starbuck 5.879006851617819\n",
      "near sushi 5.879006851617819\n",
      "near time 5.879006851617819\n",
      "near trump 5.879006851617819\n",
      "near upcoming 5.879006851617819\n",
      "near west 5.879006851617819\n",
      "near work 5.185859671057874\n",
      "nearby 4.780394562949709\n",
      "nearby crowded 5.879006851617819\n",
      "nearby dinner 5.879006851617819\n",
      "nearby lunch 5.879006851617819\n",
      "need 4.174258759379394\n",
      "need cab 5.879006851617819\n",
      "need reservation 5.185859671057874\n",
      "need table 5.473541743509655\n",
      "need taxi 5.185859671057874\n",
      "need weather 5.879006851617819\n",
      "new 4.780394562949709\n",
      "new orleans 5.879006851617819\n",
      "new york 4.962716119743664\n",
      "night 5.185859671057874\n",
      "nobu 5.879006851617819\n",
      "nobu new 5.879006851617819\n",
      "nomad 5.879006851617819\n",
      "nomad bar 5.879006851617819\n",
      "noon 5.473541743509655\n",
      "noon fry 5.879006851617819\n",
      "number 5.185859671057874\n",
      "number dead 5.879006851617819\n",
      "number hotel 5.879006851617819\n",
      "number place 5.879006851617819\n",
      "nyc 5.879006851617819\n",
      "nyc week 5.879006851617819\n",
      "office 5.879006851617819\n",
      "office manager 5.879006851617819\n",
      "old 5.879006851617819\n",
      "old red 5.879006851617819\n",
      "open 5.879006851617819\n",
      "open tonight 5.879006851617819\n",
      "opening 5.879006851617819\n",
      "opening hour 5.879006851617819\n",
      "order 4.780394562949709\n",
      "order cab 5.185859671057874\n",
      "order taxi 5.473541743509655\n",
      "orleans 5.879006851617819\n",
      "outdoor 5.879006851617819\n",
      "outdoor table 5.879006851617819\n",
      "outside 5.473541743509655\n",
      "outside noon 5.879006851617819\n",
      "oyster 5.879006851617819\n",
      "oyster depot 5.879006851617819\n",
      "palo 5.879006851617819\n",
      "palo alto 5.879006851617819\n",
      "pan 5.879006851617819\n",
      "pan highline 5.879006851617819\n",
      "paramount 5.879006851617819\n",
      "parent 5.879006851617819\n",
      "parent place 5.879006851617819\n",
      "paris 5.473541743509655\n",
      "park 4.626243883122451\n",
      "park gershwin 5.879006851617819\n",
      "park lunch 5.879006851617819\n",
      "park swing 5.879006851617819\n",
      "parking 5.473541743509655\n",
      "parking hotel 5.879006851617819\n",
      "party 4.962716119743664\n",
      "party car 5.879006851617819\n",
      "party citymapper 5.879006851617819\n",
      "party stop 5.879006851617819\n",
      "pates 5.879006851617819\n",
      "pates et 5.879006851617819\n",
      "pay 5.879006851617819\n",
      "pay credit 5.879006851617819\n",
      "peche 5.879006851617819\n",
      "peche concert 5.879006851617819\n",
      "people 3.5764217586237734\n",
      "people day 5.879006851617819\n",
      "people galli 5.879006851617819\n",
      "people katz 5.473541743509655\n",
      "people la 5.879006851617819\n",
      "people mondrian 5.879006851617819\n",
      "people mr 5.879006851617819\n",
      "people restaurant 5.185859671057874\n",
      "people sushi 5.879006851617819\n",
      "people tapestry 5.879006851617819\n",
      "people today 5.473541743509655\n",
      "people tomorrow 5.879006851617819\n",
      "phone 5.185859671057874\n",
      "phone number 5.185859671057874\n",
      "photo 5.473541743509655\n",
      "photo bar 5.879006851617819\n",
      "photo place 5.879006851617819\n",
      "pick 5.879006851617819\n",
      "pick son 5.879006851617819\n",
      "place 3.3140574941562826\n",
      "place afternoon 5.879006851617819\n",
      "place avoid 5.879006851617819\n",
      "place buy 5.879006851617819\n",
      "place favorite 5.879006851617819\n",
      "place galli 5.879006851617819\n",
      "place go 5.473541743509655\n",
      "place la 5.879006851617819\n",
      "place leave 5.879006851617819\n",
      "place near 5.879006851617819\n",
      "place pm 5.879006851617819\n",
      "place right 5.879006851617819\n",
      "place sell 5.879006851617819\n",
      "place similar 5.473541743509655\n",
      "place tomorrow 5.473541743509655\n",
      "plan 5.879006851617819\n",
      "plan slim 5.879006851617819\n",
      "plaza 5.879006851617819\n",
      "plaza locate 5.879006851617819\n",
      "pm 3.799565309937983\n",
      "pm central 5.879006851617819\n",
      "pm people 5.185859671057874\n",
      "pm tonight 5.879006851617819\n",
      "pony 5.879006851617819\n",
      "pony ride 5.879006851617819\n",
      "portion 5.879006851617819\n",
      "portion go 5.879006851617819\n",
      "pour 5.879006851617819\n",
      "pour ribbon 5.879006851617819\n",
      "practice 5.879006851617819\n",
      "price 5.879006851617819\n",
      "price range 5.879006851617819\n",
      "prince 5.879006851617819\n",
      "prince street 5.879006851617819\n",
      "problem 5.879006851617819\n",
      "problem dinner 5.879006851617819\n",
      "pub 4.962716119743664\n",
      "pub hell 5.879006851617819\n",
      "quick 5.473541743509655\n",
      "quick direction 5.879006851617819\n",
      "quick itinerary 5.879006851617819\n",
      "quiet 5.879006851617819\n",
      "quiet good 5.879006851617819\n",
      "quince 5.879006851617819\n",
      "rabbit 5.879006851617819\n",
      "rain 4.962716119743664\n",
      "rain coat 5.879006851617819\n",
      "rain minute 5.879006851617819\n",
      "rain right 5.879006851617819\n",
      "rain tomorrow 5.879006851617819\n",
      "rand 5.473541743509655\n",
      "rand birthday 5.473541743509655\n",
      "range 5.879006851617819\n",
      "range dinner 5.879006851617819\n",
      "rao 5.185859671057874\n",
      "rao crowd 5.879006851617819\n",
      "red 5.473541743509655\n",
      "red lobster 5.879006851617819\n",
      "red sauce 5.879006851617819\n",
      "reservation 4.0072046747162275\n",
      "reservation breakfast 5.879006851617819\n",
      "reservation brunch 5.879006851617819\n",
      "reservation delmonico 5.879006851617819\n",
      "reservation drink 5.879006851617819\n",
      "reservation grab 5.879006851617819\n",
      "reservation lebanese 5.879006851617819\n",
      "reservation ma 5.879006851617819\n",
      "reservation old 5.879006851617819\n",
      "reservation people 5.185859671057874\n",
      "reservation quince 5.879006851617819\n",
      "reserve 5.879006851617819\n",
      "reserve parking 5.879006851617819\n",
      "rest 5.879006851617819\n",
      "rest week 5.879006851617819\n",
      "restaurant 3.0756464707112845\n",
      "restaurant area 5.879006851617819\n",
      "restaurant balthazar 5.879006851617819\n",
      "restaurant book 5.879006851617819\n",
      "restaurant brunch 5.879006851617819\n",
      "restaurant close 5.879006851617819\n",
      "restaurant eat 5.879006851617819\n",
      "restaurant fast 5.879006851617819\n",
      "restaurant go 5.473541743509655\n",
      "restaurant like 5.879006851617819\n",
      "restaurant los 5.879006851617819\n",
      "restaurant manhattan 5.879006851617819\n",
      "restaurant near 4.269568939183719\n",
      "restaurant nearby 5.185859671057874\n",
      "restaurant pm 5.879006851617819\n",
      "restaurant se 5.879006851617819\n",
      "restaurant serve 5.879006851617819\n",
      "restaurant similar 5.879006851617819\n",
      "restaurant thanksgive 5.879006851617819\n",
      "restaurant town 5.879006851617819\n",
      "restaurant wifi 5.879006851617819\n",
      "retreat 5.879006851617819\n",
      "retreat avoid 5.879006851617819\n",
      "reunion 5.879006851617819\n",
      "reunion saturday 5.879006851617819\n",
      "ribbon 5.879006851617819\n",
      "ribbon open 5.879006851617819\n",
      "ride 4.962716119743664\n",
      "ride airport 5.879006851617819\n",
      "ride aunt 5.879006851617819\n",
      "ride current 5.879006851617819\n",
      "ride hour 5.879006851617819\n",
      "right 5.473541743509655\n",
      "road 4.780394562949709\n",
      "road avenue 5.879006851617819\n",
      "road work 5.879006851617819\n",
      "robert 5.879006851617819\n",
      "robert min 5.879006851617819\n",
      "rock 5.879006851617819\n",
      "rock cafe 5.879006851617819\n",
      "romantic 5.879006851617819\n",
      "romantic restaurant 5.879006851617819\n",
      "room 5.879006851617819\n",
      "sam 5.879006851617819\n",
      "sam wedding 5.879006851617819\n",
      "santa 5.879006851617819\n",
      "santa monica 5.879006851617819\n",
      "saturday 5.473541743509655\n",
      "saturday pm 5.879006851617819\n",
      "sauce 5.879006851617819\n",
      "sauce joint 5.879006851617819\n",
      "scientist 5.879006851617819\n",
      "scott 5.879006851617819\n",
      "scott place 5.879006851617819\n",
      "se 5.473541743509655\n",
      "se rao 5.879006851617819\n",
      "se williamsburg 5.879006851617819\n",
      "seafood 5.879006851617819\n",
      "seafood restaurant 5.879006851617819\n",
      "sebastian 5.879006851617819\n",
      "sell 5.879006851617819\n",
      "sell burritos 5.879006851617819\n",
      "send 4.174258759379394\n",
      "send current 5.473541743509655\n",
      "send eta 5.185859671057874\n",
      "send location 5.879006851617819\n",
      "send message 4.962716119743664\n",
      "serve 5.185859671057874\n",
      "serve brunch 5.879006851617819\n",
      "serve good 5.879006851617819\n",
      "serve vegetarian 5.879006851617819\n",
      "shack 5.879006851617819\n",
      "shack empire 5.879006851617819\n",
      "shake 5.879006851617819\n",
      "shake shack 5.879006851617819\n",
      "share 3.6817822742815998\n",
      "share arrival 5.879006851617819\n",
      "share current 5.473541743509655\n",
      "share estimate 5.473541743509655\n",
      "share eta 5.185859671057874\n",
      "share franz 5.879006851617819\n",
      "share location 4.4927124904979285\n",
      "share time 5.879006851617819\n",
      "short 5.879006851617819\n",
      "short way 5.879006851617819\n",
      "shoud 5.879006851617819\n",
      "shoud expect 5.879006851617819\n",
      "sia 5.879006851617819\n",
      "sia place 5.879006851617819\n",
      "similar 5.185859671057874\n",
      "similar go 5.879006851617819\n",
      "similar se 5.879006851617819\n",
      "similar starbuck 5.879006851617819\n",
      "sister 5.473541743509655\n",
      "sister stay 5.879006851617819\n",
      "sky 5.879006851617819\n",
      "sky lounge 5.879006851617819\n",
      "slim 5.879006851617819\n",
      "slim tonight 5.879006851617819\n",
      "smile 5.473541743509655\n",
      "soccer 5.879006851617819\n",
      "soccer practice 5.879006851617819\n",
      "soho 5.185859671057874\n",
      "soho grand 5.879006851617819\n",
      "soho pm 5.879006851617819\n",
      "son 5.879006851617819\n",
      "son soccer 5.879006851617819\n",
      "sophie 5.879006851617819\n",
      "sophie red 5.879006851617819\n",
      "south 5.879006851617819\n",
      "south harlem 5.879006851617819\n",
      "spot 5.473541743509655\n",
      "spot ippudo 5.879006851617819\n",
      "spot low 5.879006851617819\n",
      "square 5.879006851617819\n",
      "square people 5.879006851617819\n",
      "stadium 5.879006851617819\n",
      "standard 5.473541743509655\n",
      "standard grill 5.473541743509655\n",
      "star 5.879006851617819\n",
      "star restaurant 5.879006851617819\n",
      "starbuck 5.185859671057874\n",
      "starbuck gluten 5.879006851617819\n",
      "starbuck nearby 5.879006851617819\n",
      "state 5.185859671057874\n",
      "state building 5.185859671057874\n",
      "stay 5.473541743509655\n",
      "stay chicago 5.879006851617819\n",
      "steve 5.473541743509655\n",
      "steve address 5.879006851617819\n",
      "steve day 5.879006851617819\n",
      "stop 5.879006851617819\n",
      "stop wine 5.879006851617819\n",
      "store 5.473541743509655\n",
      "store near 5.879006851617819\n",
      "street 4.962716119743664\n",
      "suggestion 5.879006851617819\n",
      "sunday 5.879006851617819\n",
      "sunny 5.879006851617819\n",
      "sunny week 5.879006851617819\n",
      "suppose 5.879006851617819\n",
      "suppose dinner 5.879006851617819\n",
      "surf 5.879006851617819\n",
      "surf lesson 5.879006851617819\n",
      "sushi 5.185859671057874\n",
      "sushi place 5.879006851617819\n",
      "sushi restaurant 5.473541743509655\n",
      "swan 5.879006851617819\n",
      "swan oyster 5.879006851617819\n",
      "swing 5.879006851617819\n",
      "swing pony 5.879006851617819\n",
      "table 2.934567872451379\n",
      "table american 5.879006851617819\n",
      "table boozy 5.879006851617819\n",
      "table chop 5.879006851617819\n",
      "table delmonico 5.185859671057874\n",
      "table din 5.879006851617819\n",
      "table dinner 5.879006851617819\n",
      "table friday 5.473541743509655\n",
      "table good 5.185859671057874\n",
      "table group 5.879006851617819\n",
      "table hour 5.879006851617819\n",
      "table italian 5.879006851617819\n",
      "table joan 5.879006851617819\n",
      "table leave 5.879006851617819\n",
      "table near 5.473541743509655\n",
      "table nobu 5.879006851617819\n",
      "table outside 5.879006851617819\n",
      "table people 4.374929454841546\n",
      "table restaurant 4.962716119743664\n",
      "table sophie 5.879006851617819\n",
      "table standard 5.879006851617819\n",
      "tai 5.879006851617819\n",
      "tai fung 5.879006851617819\n",
      "tapestry 5.879006851617819\n",
      "tapestry pm 5.879006851617819\n",
      "tavern 5.879006851617819\n",
      "tavern green 5.879006851617819\n",
      "taxi 4.269568939183719\n",
      "taxi audrey 5.879006851617819\n",
      "taxi catch 5.879006851617819\n",
      "taxi emmit 5.879006851617819\n",
      "taxi minute 5.879006851617819\n",
      "taxi near 5.879006851617819\n",
      "taxi sebastian 5.879006851617819\n",
      "taxi tomorrow 5.879006851617819\n",
      "tell 4.962716119743664\n",
      "tell friend 5.879006851617819\n",
      "tell valery 5.879006851617819\n",
      "temperature 5.879006851617819\n",
      "temperature tomorrow 5.879006851617819\n",
      "thanksgive 5.879006851617819\n",
      "theatre 5.473541743509655\n",
      "theatre belasco 5.879006851617819\n",
      "theatre majestic 5.879006851617819\n",
      "time 4.269568939183719\n",
      "time arrival 5.185859671057874\n",
      "time employee 5.879006851617819\n",
      "time juan 5.879006851617819\n",
      "time pour 5.879006851617819\n",
      "time square 5.879006851617819\n",
      "tip 5.879006851617819\n",
      "tip know 5.879006851617819\n",
      "to 5.879006851617819\n",
      "to join 5.879006851617819\n",
      "today 4.626243883122451\n",
      "today lunch 5.185859671057874\n",
      "toll 5.185859671057874\n",
      "toll road 5.473541743509655\n",
      "tomorrow 3.627715053011324\n",
      "tomorrow evening 5.879006851617819\n",
      "tomorrow lunch 5.879006851617819\n",
      "tomorrow morning 5.473541743509655\n",
      "tomorrow night 5.473541743509655\n",
      "tomorrow pm 5.473541743509655\n",
      "tonight 4.174258759379394\n",
      "tower 5.879006851617819\n",
      "town 5.879006851617819\n",
      "town today 5.879006851617819\n",
      "tradition 5.879006851617819\n",
      "tradition cash 5.879006851617819\n",
      "traffic 3.6817822742815998\n",
      "traffic avenue 5.879006851617819\n",
      "traffic broadway 5.879006851617819\n",
      "traffic central 5.879006851617819\n",
      "traffic hotel 5.879006851617819\n",
      "traffic jam 5.473541743509655\n",
      "traffic jo 5.879006851617819\n",
      "traffic meet 5.879006851617819\n",
      "traffic portion 5.879006851617819\n",
      "traffic problem 5.879006851617819\n",
      "traffic upcoming 5.879006851617819\n",
      "traffic way 5.879006851617819\n",
      "traffic work 5.879006851617819\n",
      "transit 5.879006851617819\n",
      "transit direction 5.879006851617819\n",
      "trip 5.879006851617819\n",
      "trip los 5.879006851617819\n",
      "trump 5.879006851617819\n",
      "trump tower 5.879006851617819\n",
      "tulsa 5.879006851617819\n",
      "tulsa road 5.879006851617819\n",
      "uber 4.780394562949709\n",
      "uber dinner 5.879006851617819\n",
      "uber driver 5.879006851617819\n",
      "uber home 5.879006851617819\n",
      "uber meeting 5.879006851617819\n",
      "umbrella 5.473541743509655\n",
      "umbrella tomorrow 5.879006851617819\n",
      "umbrella walk 5.879006851617819\n",
      "upcoming 4.962716119743664\n",
      "upcoming event 5.879006851617819\n",
      "upcoming meeting 5.879006851617819\n",
      "upcoming trip 5.879006851617819\n",
      "upcoming weekend 5.879006851617819\n",
      "usually 5.879006851617819\n",
      "usually new 5.879006851617819\n",
      "valery 5.879006851617819\n",
      "valery long 5.879006851617819\n",
      "vegas 5.879006851617819\n",
      "vegas avoid 5.879006851617819\n",
      "vegetarian 5.879006851617819\n",
      "vegetarian food 5.879006851617819\n",
      "vertigo 5.879006851617819\n",
      "vertigo sky 5.879006851617819\n",
      "view 5.473541743509655\n",
      "view expensive 5.879006851617819\n",
      "view reserve 5.879006851617819\n",
      "village 5.879006851617819\n",
      "village tomorrow 5.879006851617819\n",
      "walk 4.4927124904979285\n",
      "walk dinner 5.879006851617819\n",
      "walk direction 5.185859671057874\n",
      "walk meeting 5.879006851617819\n",
      "walk today 5.879006851617819\n",
      "want 4.174258759379394\n",
      "want boston 5.879006851617819\n",
      "want eat 5.879006851617819\n",
      "want find 5.879006851617819\n",
      "want know 5.879006851617819\n",
      "want photo 5.879006851617819\n",
      "want reservation 5.473541743509655\n",
      "want table 5.473541743509655\n",
      "want weather 5.879006851617819\n",
      "way 4.626243883122451\n",
      "way greene 5.879006851617819\n",
      "way gym 5.879006851617819\n",
      "way meeting 5.879006851617819\n",
      "way rand 5.879006851617819\n",
      "way work 5.879006851617819\n",
      "waze 5.879006851617819\n",
      "weather 3.8641038310755547\n",
      "weather forecast 5.473541743509655\n",
      "weather good 5.879006851617819\n",
      "weather jo 5.879006851617819\n",
      "weather like 4.269568939183719\n",
      "weather paris 5.879006851617819\n",
      "wedding 5.879006851617819\n",
      "wednesday 5.879006851617819\n",
      "wednesday evening 5.879006851617819\n",
      "week 4.4927124904979285\n",
      "week end 5.879006851617819\n",
      "week well 5.879006851617819\n",
      "weekend 5.879006851617819\n",
      "well 5.185859671057874\n",
      "well donut 5.879006851617819\n",
      "well hotel 5.879006851617819\n",
      "well paramount 5.879006851617819\n",
      "west 5.473541743509655\n",
      "west street 5.879006851617819\n",
      "west village 5.879006851617819\n",
      "wifi 4.962716119743664\n",
      "wifi airbnb 5.879006851617819\n",
      "wifi near 5.879006851617819\n",
      "wifi smile 5.879006851617819\n",
      "williamsburg 5.185859671057874\n",
      "williamsburg near 5.879006851617819\n",
      "windy 5.879006851617819\n",
      "windy tomorrow 5.879006851617819\n",
      "wine 5.185859671057874\n",
      "wine bar 5.879006851617819\n",
      "wine near 5.879006851617819\n",
      "wine store 5.879006851617819\n",
      "work 4.174258759379394\n",
      "work congest 5.879006851617819\n",
      "work gym 5.879006851617819\n",
      "yesterday 5.879006851617819\n",
      "yesterday evening 5.879006851617819\n",
      "yoga 5.879006851617819\n",
      "yoga retreat 5.879006851617819\n",
      "york 4.962716119743664\n",
      "york boston 5.879006851617819\n",
      "york tonight 5.879006851617819\n"
     ]
    }
   ],
   "source": [
    "for word in all_feature_names:\n",
    "    indx = vectorizer_spacy.vocabulary_.get(word)\n",
    "    print(f\"{word} {vectorizer_spacy.idf_[indx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ff8682-abd6-4d01-9df8-9fd9c37b71b3",
   "metadata": {},
   "source": [
    "Lets look at the data initially and After transformation into vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c7e08073-62be-49f8-9fae-75d0040937d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Share my location with Hillary's sister\n",
       "1      Send my current location to my father\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "de2e501e-d02e-4c5c-a083-37f0f39112d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<262x1153 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2058 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_spacy_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "32d23684-1a0a-4381-b9d4-5af55955640f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.34216666, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_spacy_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f80f3024-6c7f-4e86-8617-dabc61b7d5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_spacy_tfidf.toarray()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e2382224-5371-45e9-a432-6b7a4e12deaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262, 1153)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_spacy_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "64d1a2f7-1327-4c15-bfaf-d04cc3adfb55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 1179)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_gensim_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7683740-d476-4634-a2dc-77dc738d4b41",
   "metadata": {},
   "source": [
    "We can see from the above that both the training and test data are spilt and then transformed into the vector form for us to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc6cf8-1fcf-4c30-9a22-3c3d72b2f2c6",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaf38b8-8395-4c72-b539-2b2986b436c6",
   "metadata": {},
   "source": [
    "Since we have 10 classes to classify into, we are going to import multinomial classification instead of binary classfication "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2bad4a-f65c-4336-a62b-425915f7f424",
   "metadata": {},
   "source": [
    "### Importing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f01c964e-efe9-4e7c-82f5-0632a35e7e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "df50ca15-2f1d-4ddf-ba6c-80b37860e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f53f8e-5bb3-4ad8-9de5-b38c762ec357",
   "metadata": {},
   "source": [
    "multi_class='multinomial' tells the model to use the multinomial (softmax) approach for multi-class classification.\n",
    "L-BFGS stands for Limited-memory Broyden–Fletcher–Goldfarb–Shanno. It is an optimization algorithm that belongs to the family of quasi-Newton methods, used to find the minimum of a function.\n",
    "In scikit-learn's LogisticRegression, the L-BFGS algorithm is used as a solver to optimize the loss function for both binary and multinomial classification problems. It is particularly effective for problems with many parameters because of its efficiency and ability to handle large datasets.\n",
    "Efficiency, suitability for multinomial logistic regression and compatibility with large datasets make it useful in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4e87921e-f6fa-4ff6-b6e8-4681acccd627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cfe294-52b4-49b9-95d0-31d2ccb176e4",
   "metadata": {},
   "source": [
    "### For Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6a9b67e2-8f78-4e13-a415-2ec15063a90e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data - Logistic Regression\n",
      "Accuracy: 0.8939393939393939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      0.92      0.96        13\n",
      "           3       1.00      0.40      0.57         5\n",
      "           4       0.85      0.85      0.85        13\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.85      1.00      0.92        17\n",
      "           8       0.60      1.00      0.75         3\n",
      "           9       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.89        66\n",
      "   macro avg       0.93      0.88      0.88        66\n",
      "weighted avg       0.91      0.89      0.89        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Raw Data - Logistic Regression\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8007a10c-59e1-4a31-847b-3e5ef8cc3509",
   "metadata": {},
   "source": [
    "### For NLTK Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b81ca51c-3c53-4ea7-a82a-8c8edff0bff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Preprocessed Data - Logistic Regression\n",
      "Accuracy: 0.8181818181818182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00         3\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      0.77      0.87        13\n",
      "           3       1.00      0.00      0.00         5\n",
      "           4       0.71      0.92      0.80        13\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.71      1.00      0.83        17\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.82        66\n",
      "   macro avg       0.94      0.77      0.75        66\n",
      "weighted avg       0.87      0.82      0.77        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_nltk_tfidf, y_train_nltk)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nltk = model.predict(X_test_nltk_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"NLTK Preprocessed Data - Logistic Regression\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_nltk, y_pred_nltk))\n",
    "print(classification_report(y_test_nltk, y_pred_nltk,zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac82e9-1832-4f7f-b0b3-2842ac8b1646",
   "metadata": {},
   "source": [
    "### For spaCy Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2b607e65-40f0-4158-ae88-17de7b5d0657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy Preprocessed Data - Logistic Regression\n",
      "Accuracy: 0.803030303030303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00         3\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      0.69      0.82        13\n",
      "           3       1.00      0.00      0.00         5\n",
      "           4       0.67      0.92      0.77        13\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.71      1.00      0.83        17\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.80        66\n",
      "   macro avg       0.94      0.76      0.74        66\n",
      "weighted avg       0.86      0.80      0.75        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_spacy_tfidf, y_train_spacy)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_spacy = model.predict(X_test_spacy_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"spaCy Preprocessed Data - Logistic Regression\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_spacy, y_pred_spacy))\n",
    "print(classification_report(y_test_spacy, y_pred_spacy,zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3b7c29-dfeb-4f4a-b8c7-9cf9b542732c",
   "metadata": {},
   "source": [
    "### For Gensim Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fd9a5ea6-59e1-475b-a3b7-fdd639c78c21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gensim Preprocessed Data - Logistic Regression\n",
      "Accuracy: 0.803030303030303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       0.90      0.69      0.78        13\n",
      "           3       1.00      0.00      0.00         5\n",
      "           4       0.73      0.85      0.79        13\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.68      1.00      0.81        17\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.80        66\n",
      "   macro avg       0.93      0.79      0.79        66\n",
      "weighted avg       0.85      0.80      0.77        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_gensim_tfidf, y_train_gensim)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_gensim = model.predict(X_test_gensim_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Gensim Preprocessed Data - Logistic Regression\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_gensim, y_pred_gensim))\n",
    "print(classification_report(y_test_gensim, y_pred_gensim, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b546c271-6ca6-4c98-9f74-c0b3e528c97f",
   "metadata": {},
   "source": [
    "### findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4500d4-bd96-469c-94c3-b9bd9b914a19",
   "metadata": {},
   "source": [
    "There seems to be some issue here, the accuracy for raw data prediction is higher compared to the preprocessed data using all the libraries which shouldn't be the case since we expect the model to perform better upon preprocessing\n",
    "\n",
    "1. High Precision and Recall for Raw Data:\n",
    "Raw Data: The raw data is achieving higher precision and recall, especially in certain classes indicating that raw data contains features (e.g., specific words, phrases, or token combinations) that are highly indicative of certain classes, and these features might be getting lost or diluted during preprocessing. Specific Classes: For instance, classes like 2, 4, and 7 perform reasonably well in terms of precision and recall across all versions. However, classes 0 and 3 show significant differences, where the raw data approach achieves some level of recall, while the preprocessed data versions tend to have very low or zero recall.\n",
    "2. Preprocessing Impact: It could have eliminated words that were critical in distinguishing between certain intents. Class 0 and 3: In preprocessed data, classes 0 and 3 have low recall, which means the model fails to correctly identify these classes in most cases. This could be due to important tokens being removed or modified during preprocessing. Preprocessing can sometimes make the data too \"clean,\" leading to a model that doesn't generalize as well because it's missing the natural language variations present in the raw text.\n",
    "3. Model Behavior on Processed Text: The classifier might not be receiving the same \"richness\" of information that is present in the raw data. This can lead to a model that is less capable of making correct predictions. Interestingly, the drop in performance is consistent across the different preprocessing techniques, which suggests that the preprocessing steps might be overly aggressive or not well-suited for this specific task.\n",
    "4. Vectorization Differences: The TF-IDF vectorization might behave differently on raw versus preprocessed text. Raw text may contain more unique tokens, which can affect the weighting of terms in the TF-IDF vectorization. Preprocessed text might reduce the uniqueness and lead to a different feature distribution.\n",
    "5. Data Quality and Noise: If raw data already has a relatively clean and structured form, additional preprocessing might not provide much benefit and could even introduce noise. For example, the SNIPS dataset if generally well-curated, so aggressive preprocessing might not be necessary.\n",
    "6. Recommendations:\n",
    "Less Aggressive Preprocessing: Consider reducing the aggressiveness of your preprocessing steps. For instance, keep stop words or avoid lemmatizing/stemming if those transformations are not beneficial.\n",
    "Feature Engineering: Instead of relying purely on the preprocessed text, consider adding back some features that might be lost during preprocessing. For example, we could include specific keywords or phrases as additional features.\n",
    "Hybrid Approach: we can also consider a hybrid approach where we combine features from both the raw and preprocessed data.\n",
    "7. Evaluation and Fine-Tuning:\n",
    "Focus on Misclassifications: Analyze where the preprocessed models are failing (e.g., classes 0 and 3) and compare those instances with the raw data model's performance. This will help you understand the specific aspects of the text that are critical for correct classification.\n",
    "Hyperparameter Tuning: Although the preprocessing might play a large role, we can also consider fine-tuning the model’s hyperparameters, such as the C parameter in logistic regression or adjusting the n-gram range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e882f2-ac9f-481a-be5d-0d0d8ab648d7",
   "metadata": {},
   "source": [
    "## Trying to address the issues by balancing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd689060-41c6-4356-a5db-3cac593c093b",
   "metadata": {},
   "source": [
    "We apply SMOT (Synthetic Minority Over Sampling Technique) technique for balancing the data and then try to train and evaluate the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0392d376-250a-40fc-9dd9-7440cfa6d30e",
   "metadata": {},
   "source": [
    "<!-- # for raw data\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# For NLTK preprocessing\n",
    "X_nltk = df_nltk['processed_text']\n",
    "y_nltk = df_nltk['label']\n",
    "\n",
    "# For spaCy preprocessing\n",
    "X_spacy = df_spacy['processed_text']\n",
    "y_spacy = df_spacy['label']\n",
    "\n",
    "# For gensim preprocessing\n",
    "X_gensim = df_gensim['processed_text']\n",
    "y_gensim = df_gensim['label']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For raw data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# For NLTK preprocessing\n",
    "X_train_nltk, X_test_nltk, y_train_nltk, y_test_nltk = train_test_split(X_nltk, y_nltk, test_size=0.2, random_state=42)\n",
    "\n",
    "# For spaCy preprocessing\n",
    "X_train_spacy, X_test_spacy, y_train_spacy, y_test_spacy = train_test_split(X_spacy, y_spacy, test_size=0.2, random_state=42)\n",
    "\n",
    "# For Gensim preprocessing\n",
    "X_train_gensim, X_test_gensim, y_train_gensim, y_test_gensim = train_test_split(X_gensim, y_gensim, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Initialize TF-IDF Vectorizer and transform the text data\n",
    "# For raw data\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# For NLTK preprocessing\n",
    "vectorizer_nltk = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train_nltk_tfidf = vectorizer_nltk.fit_transform(X_train_nltk)\n",
    "X_test_nltk_tfidf = vectorizer_nltk.transform(X_test_nltk)\n",
    "\n",
    "# For spaCy preprocessing\n",
    "vectorizer_spacy = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train_spacy_tfidf = vectorizer_spacy.fit_transform(X_train_spacy)\n",
    "X_test_spacy_tfidf = vectorizer_spacy.transform(X_test_spacy)\n",
    "\n",
    "# For Gensim preprocessing\n",
    "vectorizer_gensim = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train_gensim_tfidf = vectorizer_gensim.fit_transform(X_train_gensim)\n",
    "X_test_gensim_tfidf = vectorizer_gensim.transform(X_test_gensim) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93315233-553a-42b0-acce-aadcc4682953",
   "metadata": {},
   "source": [
    "<!-- # for raw data\n",
    "# X = df['text']\n",
    "# y = df['label']\n",
    "\n",
    "# # For NLTK preprocessing\n",
    "# X_nltk = df_nltk['processed_text']\n",
    "# y_nltk = df_nltk['label']\n",
    "\n",
    "# # For spaCy preprocessing\n",
    "# X_spacy = df_spacy['processed_text']\n",
    "# y_spacy = df_spacy['label']\n",
    "\n",
    "# # For gensim preprocessing\n",
    "# X_gensim = df_gensim['processed_text']\n",
    "# y_gensim = df_gensim['label']\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # For raw data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # For NLTK preprocessing\n",
    "# X_train_nltk, X_test_nltk, y_train_nltk, y_test_nltk = train_test_split(X_nltk, y_nltk, test_size=0.2, random_state=42)\n",
    "\n",
    "# # For spaCy preprocessing\n",
    "# X_train_spacy, X_test_spacy, y_train_spacy, y_test_spacy = train_test_split(X_spacy, y_spacy, test_size=0.2, random_state=42)\n",
    "\n",
    "# # For Gensim preprocessing\n",
    "# X_train_gensim, X_test_gensim, y_train_gensim, y_test_gensim = train_test_split(X_gensim, y_gensim, test_size=0.2, random_state=42)\n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# # Initialize TF-IDF Vectorizer and transform the text data\n",
    "# # For raw data\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "# X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# # For NLTK preprocessing\n",
    "# vectorizer_nltk = TfidfVectorizer(ngram_range=(1, 2))\n",
    "# X_train_nltk_tfidf = vectorizer_nltk.fit_transform(X_train_nltk)\n",
    "# X_test_nltk_tfidf = vectorizer_nltk.transform(X_test_nltk)\n",
    "\n",
    "# # For spaCy preprocessing\n",
    "# vectorizer_spacy = TfidfVectorizer(ngram_range=(1, 2))\n",
    "# X_train_spacy_tfidf = vectorizer_spacy.fit_transform(X_train_spacy)\n",
    "# X_test_spacy_tfidf = vectorizer_spacy.transform(X_test_spacy)\n",
    "\n",
    "# # For Gensim preprocessing\n",
    "# vectorizer_gensim = TfidfVectorizer(ngram_range=(1, 2))\n",
    "# X_train_gensim_tfidf = vectorizer_gensim.fit_transform(X_train_gensim)\n",
    "# X_test_gensim_tfidf = vectorizer_gensim.transform(X_test_gensim) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "811e415e-5d3a-4d39-938b-57a03d08b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE for raw data\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Apply SMOTE for NLTK preprocessed data\n",
    "X_train_nltk_resampled, y_train_nltk_resampled = smote.fit_resample(X_train_nltk_tfidf, y_train_nltk)\n",
    "\n",
    "# Apply SMOTE for spaCy preprocessed data\n",
    "X_train_spacy_resampled, y_train_spacy_resampled = smote.fit_resample(X_train_spacy_tfidf, y_train_spacy)\n",
    "\n",
    "# Apply SMOTE for Gensim preprocessed data\n",
    "X_train_gensim_resampled, y_train_gensim_resampled = smote.fit_resample(X_train_gensim_tfidf, y_train_gensim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b55f4e44-c32f-4275-a7d8-5ce8516cc129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data - Accuracy: 0.9545454545454546\n",
      "Raw Data - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         3\n",
      "           1       0.67      1.00      0.80         2\n",
      "           2       1.00      0.92      0.96        13\n",
      "           3       1.00      0.80      0.89         5\n",
      "           4       1.00      0.92      0.96        13\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.94      1.00      0.97        17\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.95        66\n",
      "   macro avg       0.94      0.96      0.94        66\n",
      "weighted avg       0.96      0.95      0.96        66\n",
      "\n",
      "NLTK Data - Accuracy: 0.8787878787878788\n",
      "NLTK Data - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         3\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       0.92      0.92      0.92        13\n",
      "           3       0.75      0.60      0.67         5\n",
      "           4       0.91      0.77      0.83        13\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.84      0.94      0.89        17\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.88        66\n",
      "   macro avg       0.89      0.89      0.89        66\n",
      "weighted avg       0.88      0.88      0.88        66\n",
      "\n",
      "spaCy Data - Accuracy: 0.8484848484848485\n",
      "spaCy Data - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.67      0.50         3\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      0.85      0.92        13\n",
      "           3       0.33      0.20      0.25         5\n",
      "           4       0.80      0.92      0.86        13\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       0.50      1.00      0.67         1\n",
      "           7       0.94      0.88      0.91        17\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.85        66\n",
      "   macro avg       0.80      0.85      0.81        66\n",
      "weighted avg       0.86      0.85      0.85        66\n",
      "\n",
      "Gensim Data - Accuracy: 0.8484848484848485\n",
      "Gensim Data - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         3\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       0.92      0.92      0.92        13\n",
      "           3       0.33      0.40      0.36         5\n",
      "           4       0.77      0.77      0.77        13\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      0.88      0.94        17\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.85        66\n",
      "   macro avg       0.85      0.86      0.86        66\n",
      "weighted avg       0.87      0.85      0.86        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train and evaluate for raw data\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_raw = model.predict(X_test_tfidf)\n",
    "print(\"Raw Data - Accuracy:\", accuracy_score(y_test, y_pred_raw))\n",
    "print(\"Raw Data - Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_raw))\n",
    "\n",
    "# Train and evaluate for NLTK preprocessed data\n",
    "model.fit(X_train_nltk_resampled, y_train_nltk_resampled)\n",
    "y_pred_nltk = model.predict(X_test_nltk_tfidf)\n",
    "print(\"NLTK Data - Accuracy:\", accuracy_score(y_test_nltk, y_pred_nltk))\n",
    "print(\"NLTK Data - Classification Report:\")\n",
    "print(classification_report(y_test_nltk, y_pred_nltk))\n",
    "\n",
    "# Train and evaluate for spaCy preprocessed data\n",
    "model.fit(X_train_spacy_resampled, y_train_spacy_resampled)\n",
    "y_pred_spacy = model.predict(X_test_spacy_tfidf)\n",
    "print(\"spaCy Data - Accuracy:\", accuracy_score(y_test_spacy, y_pred_spacy))\n",
    "print(\"spaCy Data - Classification Report:\")\n",
    "print(classification_report(y_test_spacy, y_pred_spacy))\n",
    "\n",
    "# Train and evaluate for Gensim preprocessed data\n",
    "model.fit(X_train_gensim_resampled, y_train_gensim_resampled)\n",
    "y_pred_gensim = model.predict(X_test_gensim_tfidf)\n",
    "print(\"Gensim Data - Accuracy:\", accuracy_score(y_test_gensim, y_pred_gensim))\n",
    "print(\"Gensim Data - Classification Report:\")\n",
    "print(classification_report(y_test_gensim, y_pred_gensim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547321f-5b98-41b7-bc56-e271e7f1d34c",
   "metadata": {},
   "source": [
    "Here’s a detailed comparison of the classification reports before and after SMOTE application, focusing on logistic regression models across different data types:\n",
    "\n",
    "After SMOTE Application\n",
    "Raw Data\n",
    "\n",
    "Accuracy: 0.9545\n",
    "Precision, Recall, F1-Score: Generally high across all classes. Improvement is significant compared to before SMOTE, especially for classes with previously lower scores.\n",
    "NLTK Preprocessed Data\n",
    "\n",
    "Accuracy: 0.8788\n",
    "Precision, Recall, F1-Score: Improved from before SMOTE, though still lower than raw data. Some classes have significantly better metrics compared to before.\n",
    "spaCy Preprocessed Data\n",
    "\n",
    "Accuracy: 0.8485\n",
    "Precision, Recall, F1-Score: Shows improvement, but still not reaching the levels seen in raw data. Improvement is noticeable but not as significant as in raw data.\n",
    "Gensim Preprocessed Data\n",
    "\n",
    "Accuracy: 0.8485\n",
    "Precision, Recall, F1-Score: Similar to spaCy, with improvements seen but still lower than the raw data.\n",
    "Summary of Changes\n",
    "Accuracy: After SMOTE, raw data shows a notable increase in accuracy (0.9545), indicating that the SMOTE application effectively balanced the class distribution, leading to better overall performance. Preprocessed data (NLTK, spaCy, Gensim) also saw improvements but did not reach the raw data's accuracy levels.\n",
    "\n",
    "Class-Specific Performance:\n",
    "\n",
    "Raw Data: Significant improvement in precision, recall, and F1-score across almost all classes, with balanced performance.\n",
    "NLTK, spaCy, Gensim: Notable improvements compared to before SMOTE, but some classes still lag behind compared to raw data results.\n",
    "Recommendations\n",
    "Continue Using SMOTE: The application of SMOTE has proven beneficial, particularly for balancing class distribution and improving model performance.\n",
    "\n",
    "Refine Preprocessing: Consider refining preprocessing steps and feature engineering to improve performance on preprocessed data. Check if SMOTE application on preprocessed data yields better results.\n",
    "\n",
    "Model Tuning: Further model tuning and evaluation with different techniques or additional data may help improve performance, especially for preprocessed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0e800b-6e77-4f23-94d0-3b6bade854d5",
   "metadata": {},
   "source": [
    "### Let us use only TF-IDF instead of using TF IDF with N - grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "95387ab5-35cb-4693-825a-d357c036364a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data - Accuracy: 0.9090909090909091\n",
      "Raw Data - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         3\n",
      "           1       0.67      1.00      0.80         2\n",
      "           2       0.92      0.92      0.92        13\n",
      "           3       0.67      0.80      0.73         5\n",
      "           4       1.00      0.85      0.92        13\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.94      0.88      0.91        17\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.91        66\n",
      "   macro avg       0.89      0.95      0.91        66\n",
      "weighted avg       0.92      0.91      0.91        66\n",
      "\n",
      "NLTK Data - Accuracy: 0.9242424242424242\n",
      "NLTK Data - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         3\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      0.92      0.96        13\n",
      "           3       1.00      0.80      0.89         5\n",
      "           4       0.92      0.92      0.92        13\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.89      0.94      0.91        17\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.92        66\n",
      "   macro avg       0.93      0.93      0.93        66\n",
      "weighted avg       0.93      0.92      0.93        66\n",
      "\n",
      "spaCy Data - Accuracy: 0.8636363636363636\n",
      "spaCy Data - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         3\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      0.85      0.92        13\n",
      "           3       0.33      0.20      0.25         5\n",
      "           4       0.76      1.00      0.87        13\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.94      0.88      0.91        17\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.86        66\n",
      "   macro avg       0.85      0.86      0.85        66\n",
      "weighted avg       0.86      0.86      0.86        66\n",
      "\n",
      "Gensim Data - Accuracy: 0.8636363636363636\n",
      "Gensim Data - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         3\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       0.92      0.92      0.92        13\n",
      "           3       0.40      0.40      0.40         5\n",
      "           4       0.79      0.85      0.81        13\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      0.88      0.94        17\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.86        66\n",
      "   macro avg       0.86      0.87      0.86        66\n",
      "weighted avg       0.87      0.86      0.87        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize TF-IDF Vectorizer and transform the text data\n",
    "#For raw data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# For NLTK preprocessing\n",
    "vectorizer_nltk = TfidfVectorizer()\n",
    "X_train_nltk_tfidf = vectorizer_nltk.fit_transform(X_train_nltk)\n",
    "X_test_nltk_tfidf = vectorizer_nltk.transform(X_test_nltk)\n",
    "\n",
    "# For spaCy preprocessing\n",
    "vectorizer_spacy = TfidfVectorizer()\n",
    "X_train_spacy_tfidf = vectorizer_spacy.fit_transform(X_train_spacy)\n",
    "X_test_spacy_tfidf = vectorizer_spacy.transform(X_test_spacy)\n",
    "\n",
    "# For Gensim preprocessing\n",
    "vectorizer_gensim = TfidfVectorizer()\n",
    "X_train_gensim_tfidf = vectorizer_gensim.fit_transform(X_train_gensim)\n",
    "X_test_gensim_tfidf = vectorizer_gensim.transform(X_test_gensim)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE for raw data\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Apply SMOTE for NLTK preprocessed data\n",
    "X_train_nltk_resampled, y_train_nltk_resampled = smote.fit_resample(X_train_nltk_tfidf, y_train_nltk)\n",
    "\n",
    "# Apply SMOTE for spaCy preprocessed data\n",
    "X_train_spacy_resampled, y_train_spacy_resampled = smote.fit_resample(X_train_spacy_tfidf, y_train_spacy)\n",
    "\n",
    "# Apply SMOTE for Gensim preprocessed data\n",
    "X_train_gensim_resampled, y_train_gensim_resampled = smote.fit_resample(X_train_gensim_tfidf, y_train_gensim)\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train and evaluate for raw data\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_raw = model.predict(X_test_tfidf)\n",
    "print(\"Raw Data - Accuracy:\", accuracy_score(y_test, y_pred_raw))\n",
    "print(\"Raw Data - Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_raw))\n",
    "\n",
    "# Train and evaluate for NLTK preprocessed data\n",
    "model.fit(X_train_nltk_resampled, y_train_nltk_resampled)\n",
    "y_pred_nltk = model.predict(X_test_nltk_tfidf)\n",
    "print(\"NLTK Data - Accuracy:\", accuracy_score(y_test_nltk, y_pred_nltk))\n",
    "print(\"NLTK Data - Classification Report:\")\n",
    "print(classification_report(y_test_nltk, y_pred_nltk))\n",
    "\n",
    "# Train and evaluate for spaCy preprocessed data\n",
    "model.fit(X_train_spacy_resampled, y_train_spacy_resampled)\n",
    "y_pred_spacy = model.predict(X_test_spacy_tfidf)\n",
    "print(\"spaCy Data - Accuracy:\", accuracy_score(y_test_spacy, y_pred_spacy))\n",
    "print(\"spaCy Data - Classification Report:\")\n",
    "print(classification_report(y_test_spacy, y_pred_spacy))\n",
    "\n",
    "# Train and evaluate for Gensim preprocessed data\n",
    "model.fit(X_train_gensim_resampled, y_train_gensim_resampled)\n",
    "y_pred_gensim = model.predict(X_test_gensim_tfidf)\n",
    "print(\"Gensim Data - Accuracy:\", accuracy_score(y_test_gensim, y_pred_gensim))\n",
    "print(\"Gensim Data - Classification Report:\")\n",
    "print(classification_report(y_test_gensim, y_pred_gensim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d22742-b8f7-4a9d-88de-7183e98f4fdf",
   "metadata": {},
   "source": [
    "Summary of Results:\n",
    "Raw Data:\n",
    "Accuracy: 0.91\n",
    "Macro Average F1-Score: 0.91\n",
    "Weighted Average F1-Score: 0.91\n",
    "\n",
    "NLTK Data:\n",
    "Accuracy: 0.92\n",
    "Macro Average F1-Score: 0.93\n",
    "Weighted Average F1-Score: 0.93\n",
    "\n",
    "spaCy Data:\n",
    "Accuracy: 0.86\n",
    "Macro Average F1-Score: 0.85\n",
    "Weighted Average F1-Score: 0.86\n",
    "\n",
    "Gensim Data:\n",
    "Accuracy: 0.86\n",
    "Macro Average F1-Score: 0.86\n",
    "Weighted Average F1-Score: 0.87\n",
    "Analysis\n",
    "Best Performing Preprocessing:\n",
    "\n",
    "NLTK Data achieved the highest accuracy (0.92) and F1-scores (both macro and weighted). This indicates that the preprocessing performed by NLTK provided the most useful features for the model.\n",
    "\n",
    "Raw Data:\n",
    "Raw Data performed well with an accuracy of 0.91 and decent F1-scores. It’s a strong baseline, suggesting that even without specialized preprocessing, the model performs quite well.\n",
    "spaCy and Gensim Data:\n",
    "\n",
    "spaCy and Gensim preprocessing resulted in lower performance, with accuracy and F1-scores both at 0.86. This suggests that the preprocessing methods from these libraries may not have been as effective in extracting useful features compared to the raw data or NLTK preprocessing.\n",
    "Observations\n",
    "\n",
    "Preprocessing Impact: The choice of preprocessing technique significantly affects model performance. NLTK preprocessing appears to enhance the model's ability to classify correctly, while spaCy and Gensim do not provide as much benefit in this instance.\n",
    "\n",
    "Model Consistency: The logistic regression model performs consistently across different preprocessing methods, but its effectiveness depends on the quality of the features provided by each preprocessing step.\n",
    "\n",
    "Recommendations\n",
    "Explore NLTK Preprocessing: Since NLTK preprocessing yielded the best results, consider experimenting further with different configurations or additional preprocessing steps within NLTK.\n",
    "\n",
    "Review spaCy and Gensim Preprocessing: Investigate the preprocessing steps used in spaCy and Gensim. Adjusting parameters or combining methods might improve their effectiveness.\n",
    "\n",
    "Cross-Validation: To ensure robustness, use cross-validation to validate these results and confirm that NLTK preprocessing consistently outperforms others across different data splits.\n",
    "\n",
    "Feature Engineering: Beyond TF-IDF, explore other feature extraction methods or combinations (e.g., word embeddings, topic modelling) to enhance the text representation further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eb746c-7310-4ad4-a203-d8b3b408cda4",
   "metadata": {},
   "source": [
    "### Lets perform K-cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1962b7-4334-4284-8bfc-921c975c4453",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "69460f0c-f4d3-4847-840c-8671f338f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df08118-c578-4230-9427-88c619143cbc",
   "metadata": {},
   "source": [
    "Let's define a function for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "592f54d9-50f0-4fb8-8d6a-35576475efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate_model(X_resampled_vectorized, y_resampled):\n",
    "    # Initialize Logistic Regression or any other classifier\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(model, X_resampled_vectorized, y_resampled, cv=5, scoring='accuracy')\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f3f81577-59a3-45f4-bc19-54adab3d3d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data - Accuracy Scores: [0.94339623 0.9245283  0.97169811 1.         1.        ]\n",
      "Raw Data - Mean Accuracy: 0.9679245283018869\n",
      "NLTK Data - Accuracy Scores: [0.90566038 0.93396226 0.98113208 1.         1.        ]\n",
      "NLTK Data - Mean Accuracy: 0.9641509433962264\n",
      "spaCy Data - Accuracy Scores: [0.9245283  0.93396226 0.98113208 0.98113208 1.        ]\n",
      "spaCy Data - Mean Accuracy: 0.9641509433962264\n",
      "Gensim Data - Accuracy Scores: [0.93396226 0.96226415 0.94339623 0.98113208 1.        ]\n",
      "Gensim Data - Mean Accuracy: 0.9641509433962264\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate raw data\n",
    "scores_raw = evaluate_model(X_train_resampled, y_train_resampled)\n",
    "print(f\"Raw Data - Accuracy Scores: {scores_raw}\")\n",
    "print(f\"Raw Data - Mean Accuracy: {scores_raw.mean()}\")\n",
    "\n",
    "# Evaluate NLTK preprocessed data\n",
    "scores_nltk = evaluate_model(X_train_nltk_resampled, y_train_nltk_resampled)\n",
    "print(f\"NLTK Data - Accuracy Scores: {scores_nltk}\")\n",
    "print(f\"NLTK Data - Mean Accuracy: {scores_nltk.mean()}\")\n",
    "\n",
    "# Evaluate spaCy preprocessed data\n",
    "scores_spacy = evaluate_model(X_train_spacy_resampled, y_train_spacy_resampled)\n",
    "print(f\"spaCy Data - Accuracy Scores: {scores_spacy}\")\n",
    "print(f\"spaCy Data - Mean Accuracy: {scores_spacy.mean()}\")\n",
    "\n",
    "# Evaluate Gensim preprocessed data\n",
    "scores_gensim = evaluate_model(X_train_gensim_resampled, y_train_gensim_resampled)\n",
    "print(f\"Gensim Data - Accuracy Scores: {scores_gensim}\")\n",
    "print(f\"Gensim Data - Mean Accuracy: {scores_gensim.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79427b4-cac9-4e82-a7c2-6d73b7f21407",
   "metadata": {},
   "source": [
    "Cross-validation results show that your different preprocessing methods (raw, NLTK, spaCy, Gensim) are performing quite well, with mean accuracies ranging from approximately 96.4% to 96.8%\n",
    "\n",
    "Cross-Validation Results\n",
    "Raw Data:\n",
    "Accuracy Scores: [0.943, 0.925, 0.972, 1.000, 1.000]\n",
    "Mean Accuracy: 0.968\n",
    "\n",
    "NLTK Data:\n",
    "Accuracy Scores: [0.906, 0.934, 0.981, 1.000, 1.000]\n",
    "Mean Accuracy: 0.964\n",
    "\n",
    "spaCy Data:\n",
    "Accuracy Scores: [0.925, 0.934, 0.981, 0.981, 1.000]\n",
    "Mean Accuracy: 0.964\n",
    "\n",
    "Gensim Data:\n",
    "Accuracy Scores: [0.934, 0.962, 0.943, 0.981, 1.000]\n",
    "Mean Accuracy: 0.964\n",
    "\n",
    "Observations\n",
    "Consistency Across Methods:\n",
    "The accuracies are consistently high across all preprocessing methods, indicating that your model is robust to different types of text preprocessing.\n",
    "\n",
    "Raw Data:\n",
    "Slightly higher mean accuracy compared to other methods. This might suggest that the raw text data, without additional preprocessing, is already quite informative for your model.\n",
    "\n",
    "NLTK, spaCy, Gensim Data:\n",
    "All perform similarly, with very close mean accuracies. This suggests that these preprocessing techniques are effectively handling the text data, and the model's performance is quite comparable.\n",
    "\n",
    "Further Analysis:\n",
    "Let's try using Bag of words for cross-validation and find out the differences in results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03110a8c-dac2-4cc1-a336-78df278ef292",
   "metadata": {},
   "source": [
    "Let's define a function for cross-validation using Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "313065a9-fd4e-4a2c-bb19-9c352afffc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data with BoW - Accuracy Scores: [0.86792453 0.79245283 0.88461538 0.86538462 0.94230769]\n",
      "Raw Data with BoW - Mean Accuracy: 0.8705370101596517\n",
      "NLTK Data with BoW - Accuracy Scores: [0.86792453 0.73584906 0.80769231 0.80769231 0.84615385]\n",
      "NLTK Data with BoW - Mean Accuracy: 0.8130624092888242\n",
      "spaCy Data with BoW - Accuracy Scores: [0.86792453 0.73584906 0.84615385 0.84615385 0.90384615]\n",
      "spaCy Data with BoW - Mean Accuracy: 0.8399854862119014\n",
      "Gensim Data with BoW - Accuracy Scores: [0.81132075 0.79245283 0.86538462 0.80769231 0.84615385]\n",
      "Gensim Data with BoW - Mean Accuracy: 0.8246008708272858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Create a pipeline with CountVectorizer and SMOTE\n",
    "pipeline = ImbPipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Evaluate Bag of Words for raw data\n",
    "scores_raw_bow = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Raw Data with BoW - Accuracy Scores: {scores_raw_bow}\")\n",
    "print(f\"Raw Data with BoW - Mean Accuracy: {scores_raw_bow.mean()}\")\n",
    "\n",
    "# Evaluate Bag of Words for preprocessed data\n",
    "scores_nltk_bow = cross_val_score(pipeline, X_train_nltk, y_train_nltk, cv=5, scoring='accuracy')\n",
    "print(f\"NLTK Data with BoW - Accuracy Scores: {scores_nltk_bow}\")\n",
    "print(f\"NLTK Data with BoW - Mean Accuracy: {scores_nltk_bow.mean()}\")\n",
    "\n",
    "scores_spacy_bow = cross_val_score(pipeline, X_train_spacy, y_train_spacy, cv=5, scoring='accuracy')\n",
    "print(f\"spaCy Data with BoW - Accuracy Scores: {scores_spacy_bow}\")\n",
    "print(f\"spaCy Data with BoW - Mean Accuracy: {scores_spacy_bow.mean()}\")\n",
    "\n",
    "scores_gensim_bow = cross_val_score(pipeline, X_train_gensim, y_train_gensim, cv=5, scoring='accuracy')\n",
    "print(f\"Gensim Data with BoW - Accuracy Scores: {scores_gensim_bow}\")\n",
    "print(f\"Gensim Data with BoW - Mean Accuracy: {scores_gensim_bow.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bac566-8e00-41d7-b6eb-86c6d7def38e",
   "metadata": {},
   "source": [
    "Comparing results from the Bag of Words (BoW) model with previous results from the TF-IDF model:\n",
    "\n",
    "Bag of Words (BoW) Results:\n",
    "\n",
    "Raw Data with BoW\n",
    "Accuracy Scores: [0.8679, 0.7925, 0.8846, 0.8654, 0.9423]\n",
    "Mean Accuracy: 0.8705\n",
    "\n",
    "NLTK Data with BoW\n",
    "Accuracy Scores: [0.8679, 0.7358, 0.8077, 0.8077, 0.8462]\n",
    "Mean Accuracy: 0.8131\n",
    "\n",
    "spaCy Data with BoW\n",
    "Accuracy Scores: [0.8679, 0.7358, 0.8462, 0.8462, 0.9038]\n",
    "Mean Accuracy: 0.8400\n",
    "\n",
    "Gensim Data with BoW\n",
    "Accuracy Scores: [0.8113, 0.7925, 0.8654, 0.8077, 0.8462]\n",
    "Mean Accuracy: 0.8246\n",
    "\n",
    "TF-IDF Results:\n",
    "Raw Data with TF-IDF\n",
    "Accuracy Scores: [0.9434, 0.9245, 0.9717, 1.0000, 1.0000]\n",
    "Mean Accuracy: 0.9679\n",
    "\n",
    "NLTK Data with TF-IDF\n",
    "Accuracy Scores: [0.9057, 0.9340, 0.9811, 1.0000, 1.0000]\n",
    "Mean Accuracy: 0.9642\n",
    "\n",
    "spaCy Data with TF-IDF\n",
    "Accuracy Scores: [0.9245, 0.9340, 0.9811, 0.9811, 1.0000]\n",
    "Mean Accuracy: 0.9642\n",
    "\n",
    "Gensim Data with TF-IDF\n",
    "Accuracy Scores: [0.9340, 0.9623, 0.9434, 0.9811, 1.0000]\n",
    "Mean Accuracy: 0.9642\n",
    "\n",
    "Comparison:\n",
    "Raw Data:\n",
    "BoW Mean Accuracy: 0.8705\n",
    "TF-IDF Mean Accuracy: 0.9679\n",
    "TF-IDF is significantly better than BoW in terms of mean accuracy for raw data.\n",
    "\n",
    "NLTK Data:\n",
    "BoW Mean Accuracy: 0.8131\n",
    "TF-IDF Mean Accuracy: 0.9642\n",
    "TF-IDF performs better than BoW.\n",
    "\n",
    "spaCy Data:\n",
    "BoW Mean Accuracy: 0.8400\n",
    "TF-IDF Mean Accuracy: 0.9642\n",
    "TF-IDF outperforms BoW.\n",
    "Gensim Data:\n",
    "\n",
    "BoW Mean Accuracy: 0.8246\n",
    "TF-IDF Mean Accuracy: 0.9642\n",
    "TF-IDF performs better than BoW.\n",
    "\n",
    "Conclusion:\n",
    "TF-IDF consistently provides higher accuracy compared to BoW across all preprocessing methods. This suggests that TF-IDF is better suited for capturing the importance of terms in the classification tasks compared to the BoW model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b03a59-b733-4ecf-bcbe-0cec07154a33",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Objective:\n",
    "The goal of this project was to evaluate the performance of different text preprocessing methods and their impact on the accuracy of a logistic regression model for text classification.\n",
    "\n",
    "Approach:\n",
    "Data Preparation and Preprocessing:\n",
    "\n",
    "Text Data: The dataset was preprocessed using various techniques:\n",
    "Raw Data: Directly used without any preprocessing.\n",
    "NLTK Preprocessing: Text was tokenized, cleaned, and normalized using NLTK.\n",
    "spaCy Preprocessing: Text was processed using spaCy's tokenization and lemmatization.\n",
    "Gensim Preprocessing: Text was processed using Gensim's tokenization and other preprocessing steps.\n",
    "Feature Extraction:\n",
    "\n",
    "TF-IDF Vectorization: Term Frequency-Inverse Document Frequency (TF-IDF) was used to transform the text data into numerical features. Separate TF-IDF vectorizers were applied for each preprocessing method.\n",
    "Handling Imbalance:\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique): Applied to the resampled data to address class imbalance in the training sets.\n",
    "Model Training and Evaluation:\n",
    "\n",
    "Model: Logistic Regression with max_iter=1000 and random_state=42.\n",
    "Cross-Validation: A 5-fold cross-validation was performed to evaluate the model's performance for each preprocessing method.\n",
    "Metrics: Accuracy scores and classification reports were generated for each preprocessing method.\n",
    "Results:\n",
    "\n",
    "Raw Data: Mean accuracy of 0.968, with accuracy scores ranging from 0.925 to 1.000.\n",
    "NLTK Data: Mean accuracy of 0.964, with accuracy scores ranging from 0.906 to 1.000.\n",
    "spaCy Data: Mean accuracy of 0.964, with accuracy scores ranging from 0.925 to 1.000.\n",
    "Gensim Data: Mean accuracy of 0.964, with accuracy scores ranging from 0.934 to 1.000.\n",
    "Observations:\n",
    "\n",
    "Consistency: All preprocessing methods performed well, with mean accuracies very close to each other, showing the stability of the logistic regression model across different preprocessing techniques.\n",
    "Highest Performance: Raw Data preprocessing achieved the highest mean accuracy, though differences among methods were minimal.\n",
    "Conclusion:\n",
    "\n",
    "The logistic regression model was effective across all preprocessing methods, achieving high accuracy. The choice of preprocessing method has a minimal impact on the model's performance. Further improvements could involve exploring other classifiers, hyperparameters, or additional features for this data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
